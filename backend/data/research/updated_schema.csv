id,name,description,assurance_goals,category_tags,example_use_cases,limitations,resources,intended_user,required_competencies,lifecycle_stage,complexity_rating,computational_cost_rating,goal_specific_attributes
1,"SHAP (SHapley Additive exPlanations)","Assigns importance values to each feature by computing their contribution to individual predictions, based on Shapley values from cooperative game theory.","Explainability","#explainability/feature_analysis/importance_and_attribution","[{""description"": ""Explaining individual predictions in complex models like neural networks or ensemble models."", ""goal"": ""Explainability""}]","Computationally expensive for large models or many features; assumptions like feature independence can affect accuracy of explanations.","[{""type"": ""Paper"", ""title"": ""A Unified Approach to Interpreting Model Predictions (NIPS 2017)"", ""url"": ""https://arxiv.org/abs/1705.07874""}, {""type"": ""GitHub"", ""title"": ""SHAP Library"", ""url"": ""https://github.com/slundberg/shap""}]","Data Scientists, ML Engineers","Python Programming, Machine Learning Basics, Feature Engineering","Model Testing & Validation, Model Documentation",3,3,"{""model_dependency"": ""Model-Agnostic"", ""explanation_scope"": ""Global, Local""}"
79,"SHAP Values for Fairness","Uses SHAP (SHapley Additive exPlanations) to attribute model predictions to input features, helping to identify bias contributions.","Fairness, Explainability","#fairness/interpretability_and_explainability/feature_attribution_methods, #explainability/feature_analysis","[{""description"": ""Explaining biased predictions in loan approvals by examining feature contributions."", ""goal"": ""Fairness""}]","Identifies feature contributions to bias but doesn't automatically mitigate it; interpretation requires understanding SHAP outputs, and correlated features can distribute bias attribution, complicating conclusions.","[{""type"": ""Paper"", ""title"": ""Explaining Bias: SHAP values for Fairness Analysis"", ""url"": ""https://arxiv.org/abs/2011.03045""}]","ML Engineers, Ethics Researchers, Compliance Officers","Python Programming, Fairness Metrics, Statistics, SHAP Understanding","Model Testing & Validation, Model Documentation",3,3,"{""model_dependency"": ""Model-Agnostic"", ""explanation_scope"": ""Global, Local"", ""fairness_approach"": ""Individual Fairness""}"