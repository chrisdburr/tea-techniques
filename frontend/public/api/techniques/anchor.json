{
  "slug": "anchor",
  "name": "ANCHOR",
  "acronym": null,
  "description": "ANCHOR generates high-precision if-then rules that explain individual predictions by identifying the minimal set of feature conditions that guarantee a specific prediction with high confidence. It searches for 'anchor' conditions (e.g., 'age > 30 AND income < £50k') that ensure the model gives the same prediction at least 95% of the time when those conditions are met. This creates human-readable rules that users can trust as sufficient conditions for understanding why a particular decision was made.",
  "complexity_rating": 3,
  "computational_cost_rating": 3,
  "assurance_goals": [
    {
      "id": 1,
      "name": "Explainability"
    },
    {
      "id": 6,
      "name": "Transparency"
    }
  ],
  "tags": [
    {
      "name": "applicable-models/agnostic",
      "id": 1
    },
    {
      "name": "assurance-goal-category/explainability",
      "id": 17
    },
    {
      "name": "assurance-goal-category/transparency",
      "id": 31
    },
    {
      "name": "data-requirements/no-special-requirements",
      "id": 39
    },
    {
      "name": "data-type/any",
      "id": 46
    },
    {
      "name": "evidence-type/quantitative-metric",
      "id": 59
    },
    {
      "name": "expertise-needed/statistics",
      "id": 79
    },
    {
      "name": "explanatory-scope/local",
      "id": 81
    },
    {
      "name": "lifecycle-stage/model-development",
      "id": 92
    },
    {
      "name": "technique-type/algorithmic",
      "id": 107
    }
  ],
  "related_techniques": [
    "shapley-additive-explanations",
    "integrated-gradients",
    "deeplift",
    "layer-wise-relevance-propagation",
    "local-interpretable-model-agnostic-explanations",
    "contrastive-explanation-method"
  ],
  "related_technique_slugs": [
    "shapley-additive-explanations",
    "integrated-gradients",
    "deeplift",
    "layer-wise-relevance-propagation",
    "local-interpretable-model-agnostic-explanations",
    "contrastive-explanation-method"
  ],
  "resources": [
    {
      "title": "Anchors: High-Precision Model-Agnostic Explanations",
      "url": "https://homes.cs.washington.edu/~marcotcr/aaai18.pdf",
      "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"],
      "publication_date": "2018",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "marcotcr/anchor",
      "url": "https://github.com/marcotcr/anchor",
      "authors": "",
      "publication_date": null,
      "source_type": "software_package",
      "resource_type": "documentation"
    },
    {
      "title": "alibi/alibi",
      "url": "https://github.com/SeldonIO/alibi",
      "authors": "",
      "publication_date": null,
      "source_type": "software_package",
      "resource_type": "documentation"
    },
    {
      "title": "Interpretable Machine Learning - Anchors",
      "url": "https://christophm.github.io/interpretable-ml-book/anchors.html",
      "authors": "",
      "publication_date": null,
      "source_type": "documentation",
      "resource_type": "documentation"
    }
  ],
  "example_use_cases": [
    {
      "description": "Explaining loan application decisions with rules like 'IF credit_score > 650 AND debt_ratio < 0.4 THEN approval = 95% likely', giving applicants clear, actionable conditions they can understand and potentially improve.",
      "goal": "Explainability"
    },
    {
      "description": "Generating diagnostic rules for medical predictions such as 'IF fever > 38.5°C AND white_blood_cells > 12,000 THEN infection = 92% likely', helping clinicians validate automated diagnoses with trusted clinical indicators.",
      "goal": "Explainability"
    },
    {
      "description": "Creating transparent hiring decisions with rules like 'IF experience >= 3_years AND degree = relevant THEN hire = 89% likely', providing clear justification for recruitment decisions that can be audited for fairness.",
      "goal": "Transparency"
    }
  ],
  "limitations": [
    {
      "description": "Limited to local explanations for individual instances, cannot provide global insights about overall model behaviour."
    },
    {
      "description": "Requires discretisation of continuous features, which can lose important nuanced information and create arbitrary thresholds."
    },
    {
      "description": "May fail to find suitable anchor rules if precision requirements are too strict or if the prediction space is highly complex."
    },
    {
      "description": "Computationally expensive as it requires extensive sampling to validate rule precision, especially for high-dimensional data."
    }
  ]
}
