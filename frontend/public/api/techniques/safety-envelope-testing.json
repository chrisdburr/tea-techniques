{
  "slug": "safety-envelope-testing",
  "name": "Safety Envelope Testing",
  "acronym": null,
  "description": "Safety envelope testing systematically evaluates AI system performance at the boundaries of its intended operational domain to identify potential failure modes before deployment. The technique involves defining the system's operational design domain (ODD), creating test scenarios that approach or exceed these boundaries, and measuring performance degradation as conditions become more challenging. By testing edge cases, environmental extremes, and boundary conditions, it reveals where the system transitions from safe to unsafe operation, enabling the establishment of clear operational limits and safety margins for deployment.",
  "complexity_rating": 4,
  "computational_cost_rating": 4,
  "assurance_goals": [
    {
      "id": 7,
      "name": "Safety"
    },
    {
      "id": 3,
      "name": "Reliability"
    }
  ],
  "tags": [
    {
      "name": "applicable-models/agnostic",
      "id": 1
    },
    {
      "name": "assurance-goal-category/safety",
      "id": 29
    },
    {
      "name": "assurance-goal-category/reliability",
      "id": 27
    },
    {
      "name": "data-requirements/test-scenarios",
      "id": 44
    },
    {
      "name": "data-type/any",
      "id": 46
    },
    {
      "name": "evidence-type/quantitative-metric",
      "id": 59
    },
    {
      "name": "evidence-type/boundary-analysis",
      "id": 50
    },
    {
      "name": "expertise-needed/domain-expertise",
      "id": 66
    },
    {
      "name": "expertise-needed/safety-engineering",
      "id": 75
    },
    {
      "name": "lifecycle-stage/model-development",
      "id": 92
    },
    {
      "name": "lifecycle-stage/system-deployment-and-use",
      "id": 103
    },
    {
      "name": "technique-type/testing",
      "id": 115
    }
  ],
  "related_techniques": [
    "permutation-tests",
    "cross-validation",
    "area-under-precision-recall-curve",
    "red-teaming"
  ],
  "related_technique_slugs": [
    "permutation-tests",
    "cross-validation",
    "area-under-precision-recall-curve",
    "red-teaming"
  ],
  "resources": [
    {
      "title": "On the brittleness of AI systems",
      "url": "https://arxiv.org/abs/2009.00802",
      "description": "Analysis of AI system brittleness and the need for improved testing, especially for out-of-distribution performance",
      "authors": ["Andrew J. Lohn"],
      "publication_date": "2020-09-02",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "Safety Assurance of Artificial Intelligence-Based Systems: A Systematic Literature Review",
      "url": "https://ieeexplore.ieee.org/abstract/document/9984982/",
      "description": "Comprehensive systematic literature review on safety assurance methods for AI-based systems",
      "authors": [
        "Antonio V. Silva Neto",
        "Jo√£o B. Camargo",
        "Jorge R. Almeida",
        "Paulo S. Cugnasca"
      ],
      "publication_date": "2022-12-14",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "AMLAS - Assurance of Machine Learning in Autonomous Systems",
      "url": "https://www.york.ac.uk/assuring-autonomy/guidance/amlas/amlas-tool/",
      "description": "Tool for systematically creating safety cases for machine learning components with guidance through safety envelope testing",
      "authors": "",
      "publication_date": null,
      "source_type": "documentation",
      "resource_type": "documentation"
    },
    {
      "title": "System and Safety Analysis with SysAI A Statistical Learning Framework",
      "url": "https://ntrs.nasa.gov/citations/20220009665",
      "description": "NASA technical report on statistical learning framework for system and safety analysis in AI systems",
      "authors": ["Yuning He"],
      "publication_date": "2022-07-12",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    }
  ],
  "example_use_cases": [
    {
      "description": "Testing autonomous vehicle perception systems at the limits of weather conditions, lighting, and sensor coverage to establish safe operational boundaries and determine when human intervention is required.",
      "goal": "Safety"
    },
    {
      "description": "Evaluating medical AI diagnostic systems with edge cases near decision boundaries to ensure reliable performance and identify when the system should defer to human specialists.",
      "goal": "Reliability"
    },
    {
      "description": "Assessing financial trading algorithms under extreme market conditions and volatility to prevent catastrophic losses and ensure system shutdown protocols activate appropriately.",
      "goal": "Safety"
    }
  ],
  "limitations": [
    {
      "description": "Requires comprehensive domain expertise to identify relevant boundary conditions and edge cases that could affect system safety."
    },
    {
      "description": "May be computationally expensive and time-consuming, especially for complex systems with high-dimensional operational domains."
    },
    {
      "description": "Difficult to achieve complete coverage of all possible boundary conditions, potentially missing critical edge cases."
    },
    {
      "description": "Results may not generalise to novel scenarios that fall outside the tested boundary conditions."
    },
    {
      "description": "Establishing appropriate safety thresholds and performance criteria requires careful calibration based on domain-specific risk tolerance."
    }
  ]
}
