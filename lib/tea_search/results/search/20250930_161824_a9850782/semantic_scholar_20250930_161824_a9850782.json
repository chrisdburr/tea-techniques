{
  "search_id": "20250930_161824_a9850782",
  "provider": "semantic_scholar",
  "technique_slug": "local-interpretable-model-agnostic-explanations",
  "timestamp": "2025-09-30T16:18:42.314209",
  "count": 15,
  "results": [
    {
      "title": "Deterministic Local Interpretable Model-Agnostic Explanations for Stable Explainability",
      "url": "https://www.semanticscholar.org/paper/ee5775e16b00c2a150119c0cb6a4de8c29b30cd3",
      "source": "semantic_scholar",
      "abstract": "Local Interpretable Model-Agnostic Explanations (LIME) is a popular technique used to increase the interpretability and explainability of black box Machine Learning (ML) algorithms. LIME typically creates an explanation for a single prediction by any ML model by learning a simpler interpretable model (e.g., linear classifier) around the prediction through generating simulated data around the instance by random perturbation, and obtaining feature importance through applying some form of feature s",
      "authors": [
        "Muhammad Rehman Zafar",
        "N. Khan"
      ],
      "date": "2021",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "ee5775e16b00c2a150119c0cb6a4de8c29b30cd3",
        "citation_count": 227,
        "venue": "Machine Learning and Knowledge Extraction"
      }
    },
    {
      "title": "Explaining Sentiments: Improving Explainability in Sentiment Analysis Using Local Interpretable Model-Agnostic Explanations and Counterfactual Explanations",
      "url": "https://www.semanticscholar.org/paper/96f0e5a52d3fbd5c14eaf9b49c0e56fc7d841c76",
      "source": "semantic_scholar",
      "abstract": "Sentiment analysis of social media platforms is crucial for extracting actionable insights from unstructured textual data. However, modern sentiment analysis models using deep learning lack explainability, acting as black box and limiting trust. This study focuses on improving the explainability of sentiment analysis models of social media platforms by leveraging explainable artificial intelligence (XAI). We propose a novel explainable sentiment analysis (XSA) framework incorporating intrinsic a",
      "authors": [
        "Ieee Xin Wang Member",
        "Ieee Jianhui Lyu Member",
        "Ieee J. Dinesh Peter Member",
        "Ieee B.D Byung-Gyu Kim Senior Member",
        "Ieee Keqin Parameshachari Senior Member"
      ],
      "date": "2025",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "96f0e5a52d3fbd5c14eaf9b49c0e56fc7d841c76",
        "citation_count": 0,
        "venue": "IEEE Transactions on Computational Social Systems"
      }
    },
    {
      "title": "Enhancing Visualization and Explainability of Computer Vision Models with Local Interpretable Model-Agnostic Explanations (LIME)",
      "url": "https://www.semanticscholar.org/paper/6a806b8c2bcf5ed4d026b10c4cb24f2796c0385f",
      "source": "semantic_scholar",
      "abstract": "It is important that humans understand why machine learning models behave the way they do, especially in the field of computer vision. Having methods for visualizing which regions of an image are responsible for classifying or detecting objects can be a very useful resource. One popular algorithm for doing so is Local Interpretable Model-agnostic Explanations (LIME). We introduce Sub-model Stabilized and Sub grid Superimposed LIME (SubLIME), a technique for enhancing the stability of LIME-based ",
      "authors": [
        "Nicholas Hamilton",
        "Adam J. Webb",
        "Matt Wilder",
        "Ben Hendrickson",
        "Matthew Blanck"
      ],
      "date": "2022",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "6a806b8c2bcf5ed4d026b10c4cb24f2796c0385f",
        "citation_count": 7,
        "venue": "IEEE Symposium Series on Computational Intelligence"
      }
    },
    {
      "title": "A Multiobjective Genetic Algorithm to Evolving Local Interpretable Model-Agnostic Explanations for Deep Neural Networks in Image Classification",
      "url": "https://www.semanticscholar.org/paper/8877d3da0e5ebfa84026f735bdaca78e399bd45a",
      "source": "semantic_scholar",
      "abstract": "Deep convolutional neural networks have become a dominant solution for numerous image classification tasks. However, a main criticism is the poor explainability due to the black-box characteristic, which hurdles the extensive usage of deep convolutional neural networks. To address this issue, this article proposes a new evolutionary multiobjective-based method, which aims to explain the behaviors of deep convolutional neural networks by evolving local explanations on specific images. To the best",
      "authors": [
        "Bin Wang",
        "Wenbin Pei",
        "Bing Xue",
        "Mengjie Zhang"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "8877d3da0e5ebfa84026f735bdaca78e399bd45a",
        "citation_count": 7,
        "venue": "IEEE Transactions on Evolutionary Computation"
      }
    },
    {
      "title": "Improving Local Interpretable Model-agnostic Explanations Stability",
      "url": "https://www.semanticscholar.org/paper/ede2435a2c92caaa6a3a0e2c67b02b52be6e41ac",
      "source": "semantic_scholar",
      "abstract": ": Local Interpretable Model-Agnostic Explanations (LIME) is a widely used explainable artificial intelligence (XAI) technique for tabular data. LIME explains how classifiers or regressors make decisions. However, randomization during synthetic data production makes LIME unstable, leading to distrust in its explanations. The objective of this paper is to present STable LIME (ST-LIME). ST-LIME is an extension of LIME that addresses its instability by using fixed noise to generate consistent synthe",
      "authors": [
        "Asmaa Elgezawy",
        "Hatem Abdul-kader",
        "Asmaa H. Elsaid"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "ede2435a2c92caaa6a3a0e2c67b02b52be6e41ac",
        "citation_count": 0,
        "venue": "International Journal of Intelligent Engineering and Systems"
      }
    },
    {
      "title": "Explainable machine learning techniques based on attention gate recurrent unit and local interpretable model\u2010agnostic explanations for multivariate wind speed forecasting",
      "url": "https://www.semanticscholar.org/paper/bb68facee9c98c92a381613af4d8bc83ad35c468",
      "source": "semantic_scholar",
      "abstract": "Wind power has emerged as a successful component within power systems. The ability to reliably and accurately forecast wind speed is of great importance in maintaining the security and stability of the power grid. However, the significance of explaining prediction models has often been overlooked by researchers. To address this gap, this study introduces a novel approach to wind speed forecasting that incorporates a significant decomposition method, attention\u2010based machine learning, and local ex",
      "authors": [
        "Lu Peng",
        "Sheng-Xiang Lv",
        "Lin Wang"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "bb68facee9c98c92a381613af4d8bc83ad35c468",
        "citation_count": 21,
        "venue": "Journal of Forecasting"
      }
    },
    {
      "title": "Stable local interpretable model-agnostic explanations based on a variational autoencoder",
      "url": "https://www.semanticscholar.org/paper/9b786b6f019e2f361ae2b5ee4d57bf8abb84b359",
      "source": "semantic_scholar",
      "abstract": "",
      "authors": [
        "Xu Xiang",
        "Hong Yu",
        "Ye Wang",
        "Guoyin Wang"
      ],
      "date": "2023",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "9b786b6f019e2f361ae2b5ee4d57bf8abb84b359",
        "citation_count": 14,
        "venue": "Applied intelligence (Boston)"
      }
    },
    {
      "title": "DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations Approach for Computer-Aided Diagnosis Systems",
      "url": "https://www.semanticscholar.org/paper/e5c703aba8af983c36fedf08c32a6978eadd91b9",
      "source": "semantic_scholar",
      "abstract": "Local Interpretable Model-Agnostic Explanations (LIME) is a popular technique used to increase the interpretability and explainability of black box Machine Learning (ML) algorithms. LIME typically generates an explanation for a single prediction by any ML model by learning a simpler interpretable model (e.g. linear classifier) around the prediction through generating simulated data around the instance by random perturbation, and obtaining feature importance through applying some form of feature ",
      "authors": [
        "Muhammad Rehman Zafar",
        "N. Khan"
      ],
      "date": "2019",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "e5c703aba8af983c36fedf08c32a6978eadd91b9",
        "citation_count": 163,
        "venue": "arXiv.org"
      }
    },
    {
      "title": "Interpretable ensemble deep learning model for early detection of Alzheimer's disease using local interpretable model\u2010agnostic explanations",
      "url": "https://www.semanticscholar.org/paper/df6077a8273cbe66018c7e5c84c2c8e14e015bf1",
      "source": "semantic_scholar",
      "abstract": "",
      "authors": [
        "Atefeh Aghaei",
        "M. Moghaddam",
        "H. Malek"
      ],
      "date": "2022",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "df6077a8273cbe66018c7e5c84c2c8e14e015bf1",
        "citation_count": 17,
        "venue": "International journal of imaging systems and technology (Print)"
      }
    },
    {
      "title": "Explaining Deep Convolutional Neural Networks for Image Classification by Evolving Local Interpretable Model-agnostic Explanations",
      "url": "https://www.semanticscholar.org/paper/57a66ec816b30319c6564d18920412c683b2322f",
      "source": "semantic_scholar",
      "abstract": "Deep convolutional neural networks have proven their effectiveness, and have been acknowledged as the most dominant method for image classification. However, a severe drawback of deep convolutional neural networks is poor explainability. Unfortunately, in many real-world applications, users need to understand the rationale behind the predictions of deep convolutional neural networks when determining whether they should trust the predictions or not. To resolve this issue, a novel genetic algorith",
      "authors": [
        "Bin Wang",
        "Wenbin Pei",
        "Bing Xue",
        "Mengjie Zhang"
      ],
      "date": "2022",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "57a66ec816b30319c6564d18920412c683b2322f",
        "citation_count": 6,
        "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence"
      }
    },
    {
      "title": "Early knee osteoarthritis classification using distributed explainable convolutional neural network with local interpretable model-agnostic explanations",
      "url": "https://www.semanticscholar.org/paper/727badaa3ca949e835e83345a7502a77daaaee1f",
      "source": "semantic_scholar",
      "abstract": "Knee Osteoarthritis (KOA) is a type of Knee Arthritis (KA) that causes pain, swelling, and other discomforts to the knee joints, which is quite complicated to classify using previous methods due to its various limitations such as computational cost, over-fitting issues, less reliability and so on. In this research, the classification using a distributed explainable convolutional neural network with local interpretable model-agnostic explanations (LExNN) model is proposed for knee Osteoarthritis.",
      "authors": [
        "M. Ganesh Kumar",
        "Lakshmi Narayana Gumma",
        "Saikiran Neelam",
        "Narikamalli Yaswanth",
        "Jammisetty Yedukondalu"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "727badaa3ca949e835e83345a7502a77daaaee1f",
        "citation_count": 1,
        "venue": "Engineering Research Express"
      }
    },
    {
      "title": "Skin Lesion Classification: A Deep Learning Approach with Local Interpretable Model-Agnostic Explanations (LIME) for Explainable Artificial Intelligence (XAI)",
      "url": "https://www.semanticscholar.org/paper/fea971b5a61bd668397302b21cbce9f67d6381da",
      "source": "semantic_scholar",
      "abstract": "The classification of skin cancer is crucial as the chance of survival increases significantly with timely and accurate treatment. Convolution Neural Networks (CNNs) have proven effective in classifying skin cancer. However, CNN models are often regarded as \"black boxes\u201d, due to the lack of transparency in the decision-making. Therefore, explainable artificial intelligence (XAI) has emerged as a tool for understanding AI decisions. This study employed a CNN model, VGG16, to classify five skin le",
      "authors": [
        "Sin Yi Hong",
        "Lih Poh Lin"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "fea971b5a61bd668397302b21cbce9f67d6381da",
        "citation_count": 1,
        "venue": "JOIV: International Journal on Informatics Visualization"
      }
    },
    {
      "title": "Explainable machine learning techniques for hybrid nanofluids transport characteristics: an evaluation of shapley additive and local interpretable model-agnostic explanations",
      "url": "https://www.semanticscholar.org/paper/0f9b86a02174c3b6669b241d94542dacb19666bf",
      "source": "semantic_scholar",
      "abstract": "",
      "authors": [
        "Praveen Kumar Kanti",
        "Prabhakar\u00a0Sharma",
        "V. V. Wanatasanappan",
        "N. M. Said"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "0f9b86a02174c3b6669b241d94542dacb19666bf",
        "citation_count": 9,
        "venue": "Journal of Thermal Analysis and Calorimetry"
      }
    },
    {
      "title": "Explainable Sentiment Analysis pada Ulasan Aplikasi Shopee Menggunakan Local Interpretable Model-agnostic Explanations",
      "url": "https://www.semanticscholar.org/paper/c7561527754a66e88650629a43cd5f174c957e3f",
      "source": "semantic_scholar",
      "abstract": "Seiring dengan perkembangan teknologi, pertumbuhan e-commerce mengalami peningkatan secara signifikan. Hadirnya aplikasi Shopee sebagai salah satu platform e-commerce terkemuka telah mendorong pengguna untuk melakukan transaksi belanja secara online. Dalam konteks ini, perhatian terhadap peningkatan kualitas aplikasi menjadi penting, khususnya melalui evaluasi ulasan pengguna dengan menggunakan analisis sentimen. Analisis sentimen umumnya mengadopsi pendekatan machine learning, meskipun transpar",
      "authors": [
        "Ninda Rizky Nuraeda",
        "Muhaza Liebenlito",
        "Taufik Edy Sutanto"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "c7561527754a66e88650629a43cd5f174c957e3f",
        "citation_count": 0,
        "venue": "Indonesian Journal of Computer Science"
      }
    },
    {
      "title": "Local Interpretable Model-Agnostic Explanations for Neural Ranking Models",
      "url": "https://www.semanticscholar.org/paper/8aab0e3782e0f42ed272e7ade296fa5c2c554727",
      "source": "semantic_scholar",
      "abstract": "Neural Ranking Models have shown state-of-the-art performance in Learning-To-Rank (LTR) tasks. However, they are considered black-box models. Understanding the logic behind the predictions of such black-box models is paramount for their adaptability in the real-world and high-stake decision-making domains. Local explanation techniques can help us understand the importance of features in the dataset relative to the predicted output of these black-box models. This study investigates new adaptation",
      "authors": [
        "Amir Hossein Akhavan Rahnama",
        "Laura Galera Alfaro",
        "Zhendong Wang",
        "Maria Movin"
      ],
      "date": "2024",
      "resource_type": "paper",
      "metadata": {
        "paper_id": "8aab0e3782e0f42ed272e7ade296fa5c2c554727",
        "citation_count": 0,
        "venue": "Scandinavian Conference on AI"
      }
    }
  ]
}