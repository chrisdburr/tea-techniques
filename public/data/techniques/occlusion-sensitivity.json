{
  "slug": "occlusion-sensitivity",
  "name": "Occlusion Sensitivity",
  "description": "Occlusion sensitivity tests which parts of the input are important by occluding (masking or removing) them and seeing how the model's prediction changes. For example, portions of an image can be covered up in a sliding window fashion; if the model's confidence drops significantly when a certain region is occluded, that region was important for the prediction.",
  "assurance_goals": [
    "Explainability"
  ],
  "tags": [
    "applicable-models/agnostic",
    "assurance-goal-category/explainability",
    "data-requirements/no-special-requirements",
    "data-type/image",
    "evidence-type/quantitative-metric",
    "expertise-needed/ml-engineering",
    "explanatory-scope/local",
    "lifecycle-stage/model-development",
    "technique-type/algorithmic"
  ],
  "example_use_cases": [
    {
      "description": "Testing which regions of a chest X-ray are critical for pneumonia detection by systematically covering different areas with grey patches and measuring how much the model's confidence drops for each occluded region.",
      "goal": "Explainability"
    },
    {
      "description": "Evaluating whether a facial recognition system relies on specific facial features by masking eyes, nose, mouth, or other regions to identify which areas cause the biggest drop in recognition accuracy.",
      "goal": "Explainability"
    }
  ],
  "limitations": [
    {
      "description": "Computationally expensive as it requires running inference multiple times for each region tested, scaling poorly with input size."
    },
    {
      "description": "Choice of occlusion size and shape can significantly bias results - too small may miss important features, too large may occlude multiple relevant regions simultaneously."
    },
    {
      "description": "Cannot capture interactions between multiple regions that jointly contribute to the prediction but are individually less important."
    },
    {
      "description": "Results may be misleading if the model adapts to occlusion patterns or if occluded regions are filled with unrealistic pixel values."
    }
  ],
  "resources": [
    {
      "title": "kazuto1011/grad-cam-pytorch",
      "url": "https://github.com/kazuto1011/grad-cam-pytorch",
      "source_type": "software_package"
    },
    {
      "title": "Occlusion Sensitivity Analysis with Augmentation Subspace Perturbation in Deep Feature Space",
      "url": "http://arxiv.org/pdf/2311.15022v1",
      "source_type": "technical_paper",
      "authors": [
        "Pedro Valois",
        "Koichiro Niinuma",
        "Kazuhiro Fukui"
      ],
      "publication_date": "2023-11-25"
    },
    {
      "title": "Occlusion Sensitivity â€” tf-explain documentation",
      "url": "https://tf-explain.readthedocs.io/en/latest/methods.html#occlusion-sensitivity",
      "source_type": "documentation"
    },
    {
      "title": "Adaptive occlusion sensitivity analysis for visually explaining video recognition networks",
      "url": "http://arxiv.org/pdf/2207.12859v2",
      "source_type": "technical_paper",
      "authors": [
        "Tomoki Uchiyama",
        "Naoya Sogi",
        "Satoshi Iizuka",
        "Koichiro Niinuma",
        "Kazuhiro Fukui"
      ],
      "publication_date": "2022-07-26"
    },
    {
      "title": "sicara/tf-explain",
      "url": "https://github.com/sicara/tf-explain",
      "source_type": "software_package"
    }
  ],
  "complexity_rating": 2,
  "computational_cost_rating": 4,
  "related_techniques": [
    "saliency-maps",
    "gradient-weighted-class-activation-mapping"
  ]
}