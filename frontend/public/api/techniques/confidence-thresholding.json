{
  "slug": "confidence-thresholding",
  "name": "Confidence Thresholding",
  "acronym": null,
  "description": "Confidence thresholding creates decision boundaries based on model uncertainty scores, routing predictions into different handling workflows depending on their confidence levels. High-confidence predictions (e.g., above 95%) proceed automatically, whilst medium-confidence cases (e.g., 70-95%) may trigger additional validation or human review, and low-confidence predictions (below 70%) receive extensive oversight or default to conservative fallback actions. This technique enables organisations to maintain automated efficiency for clear-cut cases whilst ensuring appropriate human intervention for uncertain decisions, balancing operational speed with risk management across safety-critical applications.",
  "complexity_rating": 2,
  "computational_cost_rating": 1,
  "assurance_goals": ["Safety", "Reliability", "Transparency"],
  "tags": [
    "applicable-models/agnostic",
    "assurance-goal-category/safety",
    "assurance-goal-category/reliability",
    "assurance-goal-category/reliability/uncertainty-quantification",
    "assurance-goal-category/transparency",
    "data-requirements/no-special-requirements",
    "data-type/any",
    "evidence-type/quantitative-metric",
    "expertise-needed/statistics",
    "expertise-needed/ml-engineering",
    "lifecycle-stage/system-deployment-and-use",
    "technique-type/algorithmic"
  ],
  "related_techniques": [
    "internal-review-boards",
    "red-teaming",
    "human-in-the-loop-safeguards",
    "runtime-monitoring-and-circuit-breakers"
  ],
  "resources": [
    {
      "title": "A Novel Dynamic Confidence Threshold Estimation AI Algorithm for Enhanced Object Detection",
      "url": "https://www.semanticscholar.org/paper/93cda7adfa043c969639e094d6c27b1c4d507208",
      "authors": ["Mounika Thatikonda", "M. Pk", "Fathi H. Amsaad"],
      "publication_date": null,
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "Improving speech recognition accuracy with multi-confidence thresholding",
      "url": "https://www.semanticscholar.org/paper/bef1c8668115675f786e5a3c6d165f268e399e9d",
      "authors": ["Shuangyu Chang"],
      "publication_date": null,
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "Improving the Robustness and Generalization of Deep Neural Network with Confidence Threshold Reduction",
      "url": "http://arxiv.org/pdf/2206.00913v2",
      "authors": [
        "Xiangyuan Yang",
        "Jie Lin",
        "Hanlin Zhang",
        "Xinyu Yang",
        "Peng Zhao"
      ],
      "publication_date": "2022-06-02",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    }
  ],
  "example_use_cases": [
    {
      "description": "Implementing tiered confidence thresholds in autonomous vehicle decision-making where high-confidence lane changes (>98%) execute automatically, medium-confidence decisions (85-98%) trigger additional sensor verification, and low-confidence situations (<85%) engage conservative defensive driving modes or request human takeover.",
      "goal": "Safety"
    },
    {
      "description": "Deploying confidence thresholding in fraud detection systems where high-confidence legitimate transactions (>90%) process immediately, medium-confidence cases (70-90%) undergo additional automated checks, and low-confidence transactions (<70%) require human analyst review, ensuring system reliability through graduated response mechanisms.",
      "goal": "Reliability"
    },
    {
      "description": "Using confidence thresholds in automated loan decisions to provide clear explanations to applicants, where high-confidence approvals include simple explanations, medium-confidence decisions provide detailed reasoning about key factors, and low-confidence cases receive comprehensive explanations with guidance on potential improvements.",
      "goal": "Transparency"
    }
  ],
  "limitations": [
    {
      "description": "Many models produce poorly calibrated confidence scores that don't accurately reflect true prediction uncertainty, leading to overconfident predictions for incorrect outputs or underconfident scores for correct predictions."
    },
    {
      "description": "Threshold selection requires careful calibration and domain expertise, as inappropriate thresholds can either overwhelm human reviewers with too many cases or miss genuinely uncertain decisions that need oversight."
    },
    {
      "description": "High-confidence predictions may still be incorrect or harmful, particularly when models encounter adversarial inputs, out-of-distribution data, or systematic biases that the confidence mechanism doesn't detect."
    },
    {
      "description": "Static thresholds may become inappropriate over time as model performance degrades, data distribution shifts occur, or operational contexts change, requiring ongoing monitoring and adjustment."
    },
    {
      "description": "Implementation complexity increases significantly when managing multiple confidence levels and routing mechanisms, potentially introducing system failures or inconsistencies in how different confidence ranges are handled."
    }
  ]
}
