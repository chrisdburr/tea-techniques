{
  "slug": "shapley-additive-explanations",
  "name": "SHapley Additive exPlanations",
  "description": "SHAP explains model predictions by quantifying how much each input feature contributes to the outcome. It assigns an importance score to every feature, indicating whether it pushes the prediction towards or away from the average. The method systematically evaluates how predictions change as features are included or excluded, drawing on game theory concepts to ensure a fair distribution of contributions.",
  "assurance_goals": ["Explainability", "Fairness", "Reliability"]
}
