{
  "slug": "data-version-control",
  "name": "Data Version Control",
  "acronym": "DVC",
  "description": "Data Version Control (DVC) is a Git-like version control system specifically designed for machine learning data, models, and experiments. It tracks changes to large data files, maintains reproducible ML pipelines, and creates a complete audit trail of data transformations, model training, and evaluation processes. DVC works alongside Git to provide end-to-end lineage tracking from raw data through preprocessing, training, and deployment, enabling teams to reproduce any model version and understand exactly how datasets evolved throughout the ML lifecycle.",
  "complexity_rating": 3,
  "computational_cost_rating": 2,
  "assurance_goals": [
    {
      "id": 6,
      "name": "Transparency"
    },
    {
      "id": 3,
      "name": "Reliability"
    }
  ],
  "tags": [
    {
      "name": "applicable-models/agnostic",
      "id": 1
    },
    {
      "name": "assurance-goal-category/transparency",
      "id": 31
    },
    {
      "name": "assurance-goal-category/reliability",
      "id": 27
    },
    {
      "name": "data-requirements/no-special-requirements",
      "id": 39
    },
    {
      "name": "data-type/any",
      "id": 46
    },
    {
      "name": "evidence-type/documentation",
      "id": 53
    },
    {
      "name": "expertise-needed/software-engineering",
      "id": 77
    },
    {
      "name": "expertise-needed/ml-engineering",
      "id": 73
    },
    {
      "name": "lifecycle-stage/data-handling",
      "id": 87
    },
    {
      "name": "lifecycle-stage/model-development",
      "id": 92
    },
    {
      "name": "lifecycle-stage/system-deployment-and-use",
      "id": 103
    },
    {
      "name": "technique-type/process",
      "id": 114
    }
  ],
  "related_techniques": [
    "model-cards",
    "datasheets-for-datasets",
    "mlflow-experiment-tracking",
    "automated-documentation-generation"
  ],
  "related_technique_slugs": [
    "model-cards",
    "datasheets-for-datasets",
    "mlflow-experiment-tracking",
    "automated-documentation-generation"
  ],
  "resources": [
    {
      "title": "DVC Documentation",
      "url": "https://dvc.org/doc",
      "description": "Comprehensive official documentation covering DVC installation, data versioning, pipeline creation, and collaborative workflows with tutorials and best practices",
      "authors": "",
      "publication_date": null,
      "source_type": "documentation",
      "resource_type": "documentation"
    },
    {
      "title": "iterative/dvc",
      "url": "https://github.com/iterative/dvc",
      "description": "Official DVC open-source repository containing the complete data version control system for machine learning with Git integration",
      "authors": "",
      "publication_date": null,
      "source_type": "software_package",
      "resource_type": "documentation"
    },
    {
      "title": "DVC Tutorial - Data Version Control for Machine Learning",
      "url": "https://dvc.org/doc/start",
      "description": "Step-by-step getting started guide demonstrating DVC basics including data tracking, pipeline creation, and experiment management",
      "authors": "",
      "publication_date": null,
      "source_type": "tutorial",
      "resource_type": "documentation"
    }
  ],
  "example_use_cases": [
    {
      "description": "Tracking medical imaging dataset versions and model training pipelines to ensure reproducible research results, enabling hospitals to verify which specific data version and preprocessing steps were used for regulatory submissions.",
      "goal": "Transparency"
    },
    {
      "description": "Managing credit scoring model data pipelines with complete version control of training datasets, feature engineering steps, and model artifacts, ensuring reliable model reproduction and rollback capabilities when performance issues arise.",
      "goal": "Reliability"
    },
    {
      "description": "Maintaining pharmaceutical drug discovery data lineage across multiple research teams, tracking compound datasets, feature extraction processes, and model versions to support FDA submissions with complete experimental provenance.",
      "goal": "Transparency"
    }
  ],
  "limitations": [
    {
      "description": "Requires learning Git-like workflows and CLI commands, which may have a steep learning curve for teams unfamiliar with version control systems."
    },
    {
      "description": "Storage costs can be substantial for large datasets with frequent changes, especially when maintaining multiple versions and branches of data."
    },
    {
      "description": "Complex data pipelines with many interdependencies may require significant setup time and careful configuration to track properly."
    },
    {
      "description": "Performance can degrade with very large files or datasets due to checksumming and synchronisation overhead during operations."
    },
    {
      "description": "Team coordination becomes essential as improper branch management or merge conflicts can disrupt collaborative workflows."
    }
  ]
}
