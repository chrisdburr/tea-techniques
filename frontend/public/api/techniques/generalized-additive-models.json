{
  "slug": "generalized-additive-models",
  "name": "Generalized Additive Models",
  "acronym": "GAMs",
  "description": "An intrinsically interpretable modelling technique that extends linear models by allowing flexible, nonlinear relationships between individual features and the target whilst maintaining the additive structure that preserves transparency. Each feature's effect is modelled separately as a smooth function, visualised as a curve showing how the feature influences predictions across its range. GAMs achieve this through spline functions or other smoothing techniques that capture complex patterns in individual variables without interactions, making them particularly valuable for domains requiring both predictive accuracy and model interpretability.",
  "complexity_rating": 3,
  "computational_cost_rating": 2,
  "assurance_goals": [
    {
      "id": 6,
      "name": "Transparency"
    },
    {
      "id": 1,
      "name": "Explainability"
    },
    {
      "id": 3,
      "name": "Reliability"
    }
  ],
  "tags": [
    {
      "name": "applicable-models/gam",
      "id": 4
    },
    {
      "name": "applicable-models/linear-model",
      "id": 8
    },
    {
      "name": "assurance-goal-category/transparency",
      "id": 31
    },
    {
      "name": "assurance-goal-category/explainability",
      "id": 17
    },
    {
      "name": "assurance-goal-category/explainability/feature-analysis",
      "id": 18
    },
    {
      "name": "assurance-goal-category/explainability/feature-analysis/importance-and-attribution",
      "id": 19
    },
    {
      "name": "assurance-goal-category/reliability",
      "id": 27
    },
    {
      "name": "data-requirements/labelled-data",
      "id": 38
    },
    {
      "name": "data-type/tabular",
      "id": 48
    },
    {
      "name": "evidence-type/quantitative-metric",
      "id": 59
    },
    {
      "name": "evidence-type/visualisation",
      "id": 62
    },
    {
      "name": "expertise-needed/statistics",
      "id": 79
    },
    {
      "name": "explanatory-scope/global",
      "id": 80
    },
    {
      "name": "lifecycle-stage/project-design",
      "id": 101
    },
    {
      "name": "lifecycle-stage/model-development",
      "id": 92
    },
    {
      "name": "technique-type/algorithmic",
      "id": 107
    }
  ],
  "related_techniques": [
    "monotonicity-constraints",
    "intrinsically-interpretable-models"
  ],
  "related_technique_slugs": [
    "monotonicity-constraints",
    "intrinsically-interpretable-models"
  ],
  "resources": [
    {
      "title": "Generalized Additive Models",
      "url": "https://hastie.su.domains/Papers/gam.pdf",
      "authors": ["Trevor Hastie", "Robert Tibshirani"],
      "publication_date": "1986",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "pyGAM: Generalized Additive Models in Python",
      "url": "https://github.com/dswah/pyGAM",
      "authors": "",
      "publication_date": null,
      "source_type": "software_package",
      "resource_type": "documentation"
    },
    {
      "title": "mgcv: Mixed GAM Computation Vehicle with Automatic Smoothness Estimation",
      "url": "https://cran.r-project.org/web/packages/mgcv/index.html",
      "authors": "",
      "publication_date": null,
      "source_type": "software_package",
      "resource_type": "documentation"
    },
    {
      "title": "A Tour of pyGAM â€” pyGAM documentation",
      "url": "https://pygam.readthedocs.io/en/latest/notebooks/tour_of_pygam.html",
      "authors": "",
      "publication_date": null,
      "source_type": "tutorial",
      "resource_type": "documentation"
    }
  ],
  "example_use_cases": [
    {
      "description": "Predicting hospital readmission risk with a GAM that provides transparent, auditable risk assessments by showing how readmission probability varies nonlinearly with patient age, blood pressure, and medication adherence, enabling clinicians to understand and trust the model's reasoning for regulatory compliance.",
      "goal": "Transparency"
    },
    {
      "description": "Building a credit scoring model that explains loan decisions to applicants by visualising how income, credit history, and debt-to-income ratio individually affect approval likelihood, providing clear feature attributions that satisfy fair lending requirements and regulatory explainability mandates.",
      "goal": "Explainability"
    },
    {
      "description": "Developing an environmental monitoring system that reliably predicts air quality using GAMs to model the smooth, nonlinear relationships between weather variables, ensuring stable predictions across seasonal variations whilst maintaining interpretable relationships that environmental scientists can validate.",
      "goal": "Reliability"
    }
  ],
  "limitations": [
    {
      "description": "Cannot capture complex interactions between features unless explicitly modelled, limiting their ability to represent relationships where variables influence each other."
    },
    {
      "description": "Setup requires domain expertise to decide which features need nonlinear treatment and appropriate smoothing parameters, making model specification more challenging than linear models."
    },
    {
      "description": "Fitting process is computationally more expensive than linear models, particularly for large datasets with many features requiring smoothing."
    },
    {
      "description": "Risk of overfitting individual feature relationships if smoothing parameters are not properly regularised, potentially reducing generalisation performance."
    },
    {
      "description": "Interpretation complexity increases with the number of nonlinear features, as understanding multiple smooth curves simultaneously becomes cognitively demanding."
    }
  ]
}
