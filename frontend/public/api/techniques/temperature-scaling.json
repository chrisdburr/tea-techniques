{
  "slug": "temperature-scaling",
  "name": "Temperature Scaling",
  "acronym": null,
  "description": "Temperature scaling adjusts a model's confidence by applying a single parameter (temperature) to its predictions. When a model is too confident in its wrong answers, temperature scaling can fix this by making the predictions more realistic. It works by dividing the model's outputs by the temperature value before converting them to probabilities. Higher temperatures make the model less confident, whilst lower temperatures increase confidence. The technique maintains the model's accuracy whilst ensuring that when it says it's 90% confident, it's actually right about 90% of the time.",
  "complexity_rating": 1,
  "computational_cost_rating": 1,
  "assurance_goals": [
    {
      "id": 3,
      "name": "Reliability"
    },
    {
      "id": 6,
      "name": "Transparency"
    },
    {
      "id": 2,
      "name": "Fairness"
    }
  ],
  "tags": [
    {
      "name": "applicable-models/neural-network",
      "id": 11
    },
    {
      "name": "assurance-goal-category/reliability",
      "id": 27
    },
    {
      "name": "assurance-goal-category/transparency",
      "id": 31
    },
    {
      "name": "assurance-goal-category/fairness",
      "id": 20
    },
    {
      "name": "data-requirements/access-to-model-internals",
      "id": 34
    },
    {
      "name": "data-requirements/calibration-set",
      "id": 36
    },
    {
      "name": "data-requirements/validation-set",
      "id": 45
    },
    {
      "name": "data-type/any",
      "id": 46
    },
    {
      "name": "evidence-type/quantitative-metric",
      "id": 59
    },
    {
      "name": "explanatory-scope/global",
      "id": 80
    },
    {
      "name": "expertise-needed/statistics",
      "id": 79
    },
    {
      "name": "lifecycle-stage/model-development",
      "id": 92
    },
    {
      "name": "technique-type/algorithmic",
      "id": 107
    }
  ],
  "related_techniques": ["empirical-calibration"],
  "related_technique_slugs": ["empirical-calibration"],
  "resources": [
    {
      "title": "gpleiss/temperature_scaling",
      "url": "https://github.com/gpleiss/temperature_scaling",
      "authors": "",
      "publication_date": null,
      "source_type": "software_package",
      "resource_type": "documentation"
    },
    {
      "title": "Exploring the Impact of Temperature Scaling in Softmax for Classification and Adversarial Robustness",
      "url": "http://arxiv.org/pdf/2502.20604v1",
      "authors": ["Hao Xuan", "Bokai Yang", "Xingyu Li"],
      "publication_date": "2025-02-28",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "Neural Clamping: Joint Input Perturbation and Temperature Scaling for Neural Network Calibration",
      "url": "http://arxiv.org/pdf/2209.11604v2",
      "authors": ["Yung-Chen Tang", "Pin-Yu Chen", "Tsung-Yi Ho"],
      "publication_date": "2024-07-24",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "On Calibration of Modern Neural Networks | arXiv",
      "url": "https://arxiv.org/abs/1706.04599",
      "authors": [
        "Chuan Guo",
        "Geoff Pleiss",
        "Yu Sun",
        "Kilian Q. Weinberger"
      ],
      "publication_date": "2017-06-14",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "On the Limitations of Temperature Scaling for Distributions with Overlaps",
      "url": "http://arxiv.org/pdf/2306.00740v3",
      "authors": ["Muthu Chidambaram", "Rong Ge"],
      "publication_date": "2023-06-01",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    }
  ],
  "example_use_cases": [
    {
      "description": "Adjusting a deep learning image classifier's confidence scores to be realistic, ensuring that when it's 90% confident, it's right 90% of the time.",
      "goal": "Reliability"
    },
    {
      "description": "Making medical diagnosis model predictions more trustworthy by providing realistic confidence scores that doctors can interpret and use to make informed decisions about patient care.",
      "goal": "Transparency"
    },
    {
      "description": "Ensuring fair treatment across patient demographics by calibrating confidence scores equally across different groups, preventing systematic over-confidence in predictions for certain populations.",
      "goal": "Fairness"
    }
  ],
  "limitations": [
    {
      "description": "Only addresses calibration at the overall dataset level, not subgroup-specific miscalibration issues."
    },
    {
      "description": "Does not improve the rank ordering or accuracy of predictions, only adjusts confidence levels."
    },
    {
      "description": "Assumes that calibration errors are consistent across different types of inputs and feature values."
    },
    {
      "description": "Requires a separate validation set for temperature parameter optimisation, which may not be available in small datasets."
    }
  ]
}
