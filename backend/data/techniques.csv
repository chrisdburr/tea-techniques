id,name,description,model_dependency,assurance_goals,categories,subcategories,attributes,example_use_cases,limitations,resources
1,SHAP (SHapley Additive exPlanations),"Assigns importance values to each feature by computing their contribution to individual predictions, based on Shapley values from cooperative game theory.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}, {""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Explaining individual predictions in complex models like neural networks or ensemble models."", ""goal"": ""Explainability""}]",,[]
2,Permutation Importance,Evaluates feature importance by measuring the decrease in model accuracy when a feature's values are randomly shuffled.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Assessing feature importance in models where coefficients are not available, such as tree-based models."", ""goal"": ""Explainability""}]",,[]
3,Mean Decrease Impurity (MDI),Calculates feature importance in tree-based models by measuring how much each feature decreases impurity across all trees.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Determining important features in Random Forest classification tasks."", ""goal"": ""Explainability""}]",,[]
4,Gini Importance,Measures the total reduction of Gini impurity brought by a feature across all nodes and trees in decision trees and Random Forests.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Selecting important features when building tree-based classification models."", ""goal"": ""Explainability""}]",,[]
5,Coefficient Magnitudes (in Linear Models),"Uses the absolute values of coefficients in linear models to represent feature importance, indicating the strength and direction of relationships.",Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Interpreting which features influence housing price predictions in linear regression."", ""goal"": ""Explainability""}]",,[]
6,Integrated Gradients,Attributes feature importance by integrating gradients of the model's output with respect to inputs along a path from a baseline to the actual input.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Understanding pixel contributions in image classification with deep neural networks."", ""goal"": ""Explainability""}]",,[]
7,DeepLIFT,"Tracks changes in the output relative to a reference input, decomposing contributions from individual neurons to the final prediction in deep learning models.",Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Explaining why a neural network classifies an image as a specific object by tracing neuron activations."", ""goal"": ""Explainability""}]",,[]
8,Layer-wise Relevance Propagation (LRP),"Explains predictions by backpropagating relevance scores from the output layer to input features, distributing the prediction score layer by layer.",Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Visualising important regions in medical images for disease diagnosis using deep learning models."", ""goal"": ""Explainability""}]",,[]
9,"Variable Importance in Random Forests (MDA, MDG)",Calculates feature importance by measuring the Mean Decrease Accuracy or Mean Decrease Gini when a feature is excluded from Random Forest models.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Identifying key predictors in a Random Forest model for credit scoring."", ""goal"": ""Explainability""}]",,[]
10,Contextual Decomposition,Interprets neural networks by decomposing activations to explain predictions based on contributions of individual features or groups.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Explaining sentiment predictions in text by attributing scores to words or phrases."", ""goal"": ""Explainability""}]",,[]
11,Taylor Decomposition,Decomposes predictions into contributions from individual features using a Taylor series expansion of the model's prediction function.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Attributing feature contributions in complex models for specific predictions."", ""goal"": ""Explainability""}]",,[]
12,Sobol Indices,Quantifies the contribution of individual variables and their interactions to the output variance in sensitivity analysis.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Interaction Analysis""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Understanding parameter impacts in environmental modeling outputs."", ""goal"": ""Explainability""}]",,[]
13,Feature Interaction Detection (H-statistic),Measures feature interaction by comparing joint contributions to the model with the sum of individual contributions.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Interaction Analysis""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Identifying significant interactions in healthcare predictive models."", ""goal"": ""Explainability""}]",,[]
14,LIME (Local Interpretable Model-Agnostic Explanations),Generates local surrogate models that approximate complex model behaviour around a specific instance using interpretable models like linear models.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Model Approximation""}]","[{""category"": ""Model Approximation"", ""subcategory"": ""Local Surrogates""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Explaining why a customer was denied a loan by approximating the model's decision locally."", ""goal"": ""Explainability""}]",,[]
15,Ridge Regression Surrogates,"Uses Ridge Regression as a surrogate to approximate global behaviour of complex models, balancing simplicity and interpretability with regularisation.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Model Approximation""}]","[{""category"": ""Model Approximation"", ""subcategory"": ""Global Surrogates""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Summarising complex model behaviour for regulatory reporting in finance."", ""goal"": ""Explainability""}]",,[]
16,Partial Dependence Plots (PDP),"Visualises the relationship between one or two features and the predicted outcome, averaging out effects of other features.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Feature Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Understanding how changes in age affect predicted disease risk in medical models."", ""goal"": ""Explainability""}]",,[]
17,Accumulated Local Effects (ALE) Plots,"Similar to PDPs but account for feature interactions, providing accurate insights when features are correlated.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Feature Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Exploring the effect of house size on price predictions in real estate models with correlated features."", ""goal"": ""Explainability""}]",,[]
18,Individual Conditional Expectation (ICE) Plots,"Shows how a feature affects predictions for individual instances, highlighting heterogeneous effects across data points.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Feature Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Visualising how customers' predicted spending changes with income in consumer behaviour models."", ""goal"": ""Explainability""}]",,[]
19,Saliency Maps,Highlights important pixels in input images that most influence the output prediction in computer vision models.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Model Behaviour Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Identifying regions contributing to tumor diagnosis in medical images."", ""goal"": ""Explainability""}]",,[]
20,Grad-CAM (Gradient-weighted Class Activation Mapping),Uses gradients to produce heatmaps highlighting image regions that contribute most to the model's output.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Model Behaviour Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Visualising parts of an image leading to a 'dog' classification in image recognition models."", ""goal"": ""Explainability""}]",,[]
21,Occlusion Sensitivity,Measures prediction changes by systematically occluding parts of the input to identify important regions or features.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Model Behaviour Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Understanding which words affect sentiment prediction by masking them in NLP models."", ""goal"": ""Explainability""}]",,[]
22,Attention Mechanisms in Neural Networks,"Visualises attention weights in models like transformers, highlighting important input parts for predictions.",Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Model Behaviour Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Analysing which words a transformer model focuses on during machine translation tasks."", ""goal"": ""Explainability""}]",,[]
23,Factor Analysis,"Reduces dimensionality by identifying latent factors explaining observed variability, aiding in data interpretation.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Model Simplification""}]","[{""category"": ""Model Simplification"", ""subcategory"": ""Dimensionality Reduction""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Discovering underlying factors in psychological survey data for social science research."", ""goal"": ""Explainability""}]",,[]
24,Principal Component Analysis (PCA),"Reduces dimensionality by projecting data onto directions of maximum variance, simplifying data while retaining important information.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Dimensionality Reduction Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Visualising high-dimensional gene expression data in bioinformatics."", ""goal"": ""Explainability""}]",,[]
25,t-SNE,"A non-linear technique that visualises high-dimensional data in 2D or 3D, preserving local relationships between points.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Dimensionality Reduction Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Visualising clusters in high-dimensional word embeddings."", ""goal"": ""Explainability""}]",,[]
26,UMAP,A non-linear technique similar to t-SNE but better at preserving global data structure.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Dimensionality Reduction Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Visualising patterns in user behaviour data for marketing analysis."", ""goal"": ""Explainability""}]",,[]
27,Prototype and Criticism Models,Identifies representative (prototypes) and non-representative (criticisms) examples to summarise and highlight model behaviour.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Example-Based Methods""}]","[{""category"": ""Example-Based Methods"", ""subcategory"": ""Prototype and Criticism Methods""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Selecting representative customer profiles for targeted marketing."", ""goal"": ""Explainability""}]",,[]
28,Influence Functions,Measures the impact of training examples on model predictions to identify influential data points.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Example-Based Methods""}]","[{""category"": ""Example-Based Methods"", ""subcategory"": ""Prototype and Criticism Methods""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Debugging model predictions by identifying influential training data points."", ""goal"": ""Explainability""}]",,[]
29,Contrastive Explanation Method (CEM),"Generates explanations by identifying minimal input changes that result in different outcomes, offering counterfactual reasoning.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Example-Based Methods""}]","[{""category"": ""Example-Based Methods"", ""subcategory"": ""Counterfactual Explanations""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Explaining loan rejections by showing what changes would lead to approval."", ""goal"": ""Explainability""}]",,[]
30,"Bayesian Networks (e.g., bnlearn)",Probabilistic graphical models representing variables and their conditional dependencies for causal reasoning.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Example-Based Methods""}]","[{""category"": ""Example-Based Methods"", ""subcategory"": ""Causal Analysis""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Modeling causal relationships in gene regulatory networks."", ""goal"": ""Explainability""}]",,[]
31,ANCHOR,"Provides high-precision if-then rules for specific predictions, explaining which features are responsible for the decision.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Rule Extraction""}]","[{""category"": ""Rule Extraction"", ""subcategory"": ""Decision Rules""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Generating rules to explain individual predictions in text classification."", ""goal"": ""Explainability""}]",,[]
32,RuleFit,Combines decision rules with linear models to provide interpretable models capturing non-linear patterns.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Rule Extraction""}]","[{""category"": ""Rule Extraction"", ""subcategory"": ""Decision Rules""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Building interpretable models for predicting customer churn with rule-based explanations."", ""goal"": ""Explainability""}]",,[]
33,Monte Carlo Dropout,Uses dropout at inference time in deep learning models to estimate uncertainty by approximating Bayesian inference.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Uncertainty and Reliability""}]","[{""category"": ""Uncertainty and Reliability"", ""subcategory"": ""Confidence Estimation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Estimating prediction uncertainty in medical diagnosis models."", ""goal"": ""Explainability""}]",,[]
34,ODIN (Out-of-DIstribution detector for Neural networks),Detects out-of-distribution samples in neural networks by applying temperature scaling and input perturbations.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Uncertainty and Reliability""}]","[{""category"": ""Uncertainty and Reliability"", ""subcategory"": ""Out-of-Distribution Detection""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Identifying when an image classifier encounters novel inputs."", ""goal"": ""Explainability""}]",,[]
35,Permutation Tests,Estimates uncertainty by permuting data labels and calculating test statistics to create a null distribution in non-parametric methods.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Uncertainty and Reliability""}]","[{""category"": ""Uncertainty and Reliability"", ""subcategory"": ""Uncertainty Quantification""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Assessing the significance of model predictions in hypothesis testing."", ""goal"": ""Explainability""}]",,[]
36,"Fairness Metrics (e.g., Equalized Odds, Demographic Parity)",Evaluates models for fairness by measuring disparities in predictions across different demographic groups.,Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Fairness Explanations""}]","[{""category"": ""Fairness Explanations"", ""subcategory"": ""Bias Detection and Mitigation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Ensuring a hiring model does not discriminate based on gender or ethnicity."", ""goal"": ""Explainability""}]",,[]
37,Model Pruning,"Simplifies neural networks by removing less important weights or neurons, reducing complexity while retaining performance.",Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Model Simplification""}]","[{""category"": ""Model Simplification"", ""subcategory"": ""Model Pruning""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Reducing model size for deployment on mobile devices without significant loss in accuracy."", ""goal"": ""Explainability""}]",,[]
38,Knowledge Distillation,"Trains a simpler 'student' model to replicate the behaviour of a complex 'teacher' model, resulting in a more interpretable model.",Model-Agnostic,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Model Simplification""}]","[{""category"": ""Model Simplification"", ""subcategory"": ""Model Distillation""}]","[{""type"": ""Scope"", ""value"": ""Global""}]","[{""description"": ""Simplifying a deep neural network for faster inference in real-time applications."", ""goal"": ""Explainability""}]",,[]
39,Attention Visualisation in Transformers,Visualises attention weights in transformer-based models to show how the model focuses on different input parts during prediction.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Visualisation Techniques""}]","[{""category"": ""Visualisation Techniques"", ""subcategory"": ""Model Behaviour Visualisation""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Understanding which words a transformer model focuses on during machine translation tasks."", ""goal"": ""Explainability""}]",,[]
40,Neuron Activation Analysis,Analyses activation patterns of neurons in large language models (LLMs) to interpret their roles and the concepts they represent.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}, {""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Identifying neurons responsible for syntax or semantics in language models."", ""goal"": ""Explainability""}]",,[]
41,Prompt Sensitivity Analysis,Studies how variations in input prompts affect LLM outputs to understand model behaviour and sensitivity.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Example-Based Methods""}]","[{""category"": ""Example-Based Methods"", ""subcategory"": ""Prototype and Criticism Methods""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Evaluating how different phrasings influence an LLM's answers in question-answering tasks."", ""goal"": ""Explainability""}]",,[]
42,Causal Mediation Analysis in Language Models,Investigates causal relationships within LLMs by assessing how interventions on specific components affect outputs.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Example-Based Methods""}]","[{""category"": ""Example-Based Methods"", ""subcategory"": ""Causal Analysis""}]","[{""type"": ""Scope"", ""value"": ""Global""}, {""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Understanding how adjusting embeddings changes model responses in language generation tasks."", ""goal"": ""Explainability""}]",,[]
43,Feature Attribution with Integrated Gradients in NLP,"Applies Integrated Gradients to attribute importance of input tokens in LLMs for specific predictions, often producing visualisations.",Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Identifying words influencing text sentiment classification or topic modeling."", ""goal"": ""Explainability""}]",,[]
44,Concept Activation Vectors (CAVs),Represents human-understandable concepts as vectors in the model's latent space to analyse their influence on predictions.,Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Feature Analysis""}]","[{""category"": ""Feature Analysis"", ""subcategory"": ""Importance and Attribution""}]","[{""type"": ""Scope"", ""value"": ""Global""}, {""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Assessing how concepts like \""negativity\"" affect language model outputs."", ""goal"": ""Explainability""}]",,[]
45,In-Context Learning Analysis,"Examines how LLMs learn from examples provided in the input prompt, revealing capacity for few-shot learning.",Model-Specific,Explainability,"[{""goal"": ""Explainability"", ""category"": ""Example-Based Methods""}]","[{""category"": ""Example-Based Methods"", ""subcategory"": ""Prototype and Criticism Methods""}]","[{""type"": ""Scope"", ""value"": ""Local""}]","[{""description"": ""Analysing the effect of examples on an LLM's ability to perform a new task like translation."", ""goal"": ""Explainability""}]",,[]
46,Reweighing,Assigns weights to instances in the training data to ensure different groups are equally represented in all labels.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Pre-Processing Techniques""}]","[{""category"": ""Pre-Processing Techniques"", ""subcategory"": ""Data Transformation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Balancing gender representation in credit approval datasets before training a classifier."", ""goal"": ""Fairness""}]",,[]
47,Disparate Impact Remover,"Edits feature values to reduce dependence between features and protected attributes, aiming to mitigate disparate impact.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Pre-Processing Techniques""}]","[{""category"": ""Pre-Processing Techniques"", ""subcategory"": ""Data Transformation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Adjusting salary features to reduce gender bias in income prediction models."", ""goal"": ""Fairness""}]",,[]
48,Learning Fair Representations,Learns latent representations that encode data well but obfuscate information about protected attributes.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fair Representation Learning""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Creating unbiased data representations for hiring algorithms."", ""goal"": ""Fairness""}]",,[]
49,Fairness GAN,Employs Generative Adversarial Networks to generate fair representations of data that obfuscate protected attributes.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fair Representation Learning""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Creating unbiased datasets for training fair image recognition models."", ""goal"": ""Fairness""}]",,[]
50,Optimised Pre-Processing,Modifies training data features and labels to induce fairness while preserving data utility.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Pre-Processing Techniques""}]","[{""category"": ""Pre-Processing Techniques"", ""subcategory"": ""Data Transformation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Adjusting criminal justice data to reduce racial bias before training models."", ""goal"": ""Fairness""}]",,[]
51,Relabelling,"Changes labels of certain instances in training data to reduce bias, often based on fairness constraints.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Pre-Processing Techniques""}]","[{""category"": ""Pre-Processing Techniques"", ""subcategory"": ""Data Transformation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Modifying labels in loan default datasets to mitigate historical biases."", ""goal"": ""Fairness""}]",,[]
52,Preferential Sampling,Re-samples data with preference for certain groups to achieve fair representation in training datasets.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Pre-Processing Techniques""}]","[{""category"": ""Pre-Processing Techniques"", ""subcategory"": ""Data Transformation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Oversampling minority groups in medical data to train unbiased models."", ""goal"": ""Fairness""}]",,[]
53,Fairness Through Unawareness,"Ensures the model does not use protected attributes in decisions; however, indirect bias may persist.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Pre-Processing Techniques""}]","[{""category"": ""Pre-Processing Techniques"", ""subcategory"": ""Data Transformation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Preprocessing and Feature Engineering""}]","[{""description"": ""Removing gender as a feature in employee promotion predictions."", ""goal"": ""Fairness""}]",,[]
54,Adversarial Debiasing,Trains a model to make accurate predictions while reducing the ability of an adversary to predict protected attributes from outputs.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Adversarial Debiasing""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Developing fair classification models for loan approvals by reducing gender predictability."", ""goal"": ""Fairness""}]",,[]
55,Adversarial Debiasing for Text,Applies adversarial debiasing techniques specifically to textual data to mitigate biases in language models.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Adversarial Debiasing""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Reducing gender bias in sentiment analysis models by adversarial training on text data."", ""goal"": ""Fairness""}]",,[]
56,Fair Adversarial Networks,Extends adversarial debiasing by incorporating fairness into deep learning via adversarial training.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Adversarial Debiasing""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Reducing bias in facial recognition systems with adversarial networks."", ""goal"": ""Fairness""}]",,[]
57,Prejudice Remover Regulariser,Incorporates a fairness penalty into the learning objective to penalise models that encode biases with respect to protected attributes.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fairness-Constrained Optimisation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Training logistic regression models with fairness constraints for university admissions."", ""goal"": ""Fairness""}]",,[]
58,Meta Fair Classifier,Modifies any classifier to optimise for fairness metrics using a meta-learning algorithm.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fairness-Constrained Optimisation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Applying fairness optimisation to models in employee evaluation systems."", ""goal"": ""Fairness""}]",,[]
59,Exponentiated Gradient Reduction,"Formulates fairness as a constrained optimisation problem, using exponentiated gradient methods to find optimal classifiers.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fairness-Constrained Optimisation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Training fair classifiers for employment screening processes."", ""goal"": ""Fairness""}]",,[]
60,Fair Transfer Learning,Adapts models trained on one domain to another while preserving fairness constraints across domains.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fair Representation Learning""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Transferring fairness-aware models from one region's data to another in healthcare analytics."", ""goal"": ""Fairness""}]",,[]
61,Adaptive Sensitive Reweighting,Dynamically adjusts weights during training based on model performance across different groups.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fairness-Constrained Optimisation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Balancing performance in speech recognition across accents and dialects."", ""goal"": ""Fairness""}]",,[]
62,Multi-Accuracy Boosting,Improves accuracy uniformly across groups by correcting errors where the model performs poorly for certain groups.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fairness-Constrained Optimisation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Enhancing model performance for underrepresented groups in disease prediction."", ""goal"": ""Fairness""}]",,[]
63,Equalised Odds Post-Processing,Adjusts output probabilities to equalise true positive and false positive rates across groups.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Post-Processing Techniques""}]","[{""category"": ""Post-Processing Techniques"", ""subcategory"": ""Outcome Adjustment""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Testing & Validation""}]","[{""description"": ""Ensuring fairness in recidivism risk assessments used in judicial decisions."", ""goal"": ""Fairness""}]",,[]
64,Threshold Optimiser,Adjusts decision thresholds for different groups to satisfy fairness constraints post-training.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Post-Processing Techniques""}]","[{""category"": ""Post-Processing Techniques"", ""subcategory"": ""Outcome Adjustment""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Testing & Validation""}]","[{""description"": ""Ensuring equal acceptance rates in college admissions across demographics."", ""goal"": ""Fairness""}]",,[]
65,Reject Option Classification,"Changes decisions where the model is least certain, favouring the disadvantaged group within this uncertain region.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Post-Processing Techniques""}]","[{""category"": ""Post-Processing Techniques"", ""subcategory"": ""Outcome Adjustment""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Testing & Validation""}]","[{""description"": ""Mitigating bias in hiring decisions by adjusting uncertain predictions."", ""goal"": ""Fairness""}]",,[]
66,Calibration with Equality of Opportunity,Adjusts probabilities to achieve equal true positive rates across groups while maintaining calibration within each group.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Post-Processing Techniques""}]","[{""category"": ""Post-Processing Techniques"", ""subcategory"": ""Calibration Methods""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Testing & Validation""}]","[{""description"": ""Balancing opportunity in credit scoring across different ethnic groups."", ""goal"": ""Fairness""}]",,[]
67,Statistical Parity Difference,Measures the difference in positive outcome rates between protected and unprotected groups.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Fairness Metrics and Evaluation""}]","[{""category"": ""Fairness Metrics and Evaluation"", ""subcategory"": ""Group Fairness Metrics""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Evaluating fairness in hiring models by comparing selection rates across genders."", ""goal"": ""Fairness""}]",,[]
68,Disparate Impact,"Assesses whether decisions disproportionately affect members of a protected group, typically requiring a ratio between rates.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Fairness Metrics and Evaluation""}]","[{""category"": ""Fairness Metrics and Evaluation"", ""subcategory"": ""Group Fairness Metrics""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Checking for bias in loan approvals where minority groups are less likely to be approved."", ""goal"": ""Fairness""}]",,[]
69,Demographic Parity,"Evaluates if the outcome is independent of the protected attributes, aiming for equal outcome rates across groups.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Fairness Metrics and Evaluation""}]","[{""category"": ""Fairness Metrics and Evaluation"", ""subcategory"": ""Group Fairness Metrics""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Ensuring job advertisements are shown equally across genders."", ""goal"": ""Fairness""}]",,[]
70,Equal Opportunity Difference,"Computes the difference in true positive rates between groups, assessing fairness in terms of equal opportunity.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Fairness Metrics and Evaluation""}]","[{""category"": ""Fairness Metrics and Evaluation"", ""subcategory"": ""Group Fairness Metrics""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Assessing fairness in medical diagnosis models across age groups."", ""goal"": ""Fairness""}]",,[]
71,Average Odds Difference,Calculates the average difference in false positive and true positive rates between groups.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Fairness Metrics and Evaluation""}]","[{""category"": ""Fairness Metrics and Evaluation"", ""subcategory"": ""Group Fairness Metrics""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Measuring bias in criminal risk assessment tools."", ""goal"": ""Fairness""}]",,[]
72,Individual Fairness Metric (Consistency),"Evaluates whether similar individuals receive similar predictions, assessing fairness at an individual level.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Fairness Metrics and Evaluation""}]","[{""category"": ""Fairness Metrics and Evaluation"", ""subcategory"": ""Individual Fairness Metrics""}]","[{""type"": ""Fairness Approach"", ""value"": ""Individual Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Ensuring similar credit applicants receive similar loan decisions."", ""goal"": ""Fairness""}]",,[]
73,Algorithmic Fairness using K-NN,Uses K-nearest neighbours to assess individual fairness by comparing predictions among similar instances.,Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Fairness Metrics and Evaluation""}]","[{""category"": ""Fairness Metrics and Evaluation"", ""subcategory"": ""Individual Fairness Metrics""}]","[{""type"": ""Fairness Approach"", ""value"": ""Individual Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Evaluating fairness in personalised recommendation systems."", ""goal"": ""Fairness""}]",,[]
74,Counterfactual Fairness (Causal Modelling),Ensures predictions remain the same in a counterfactual world where protected attributes are altered.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Causal Fairness Methods""}]","[{""category"": ""Causal Fairness Methods"", ""subcategory"": ""Counterfactual Fairness""}]","[{""type"": ""Fairness Approach"", ""value"": ""Individual Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Assessing fairness in loan approvals by simulating changes in applicant's race."", ""goal"": ""Fairness""}]",,[]
75,Path-Specific Counterfactual Fairness,"Considers specific causal pathways, allowing fairness interventions on certain paths.",Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Causal Fairness Methods""}]","[{""category"": ""Causal Fairness Methods"", ""subcategory"": ""Counterfactual Fairness""}]","[{""type"": ""Fairness Approach"", ""value"": ""Individual Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Modelling fair decisions in advertising without altering legitimate causal effects."", ""goal"": ""Fairness""}]",,[]
76,Causal Fairness Assessment with Do-Calculus,Utilises causal inference techniques to assess and mitigate bias by computing interventional distributions.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Causal Fairness Methods""}]","[{""category"": ""Causal Fairness Methods"", ""subcategory"": ""Causal Inference""}]","[{""type"": ""Fairness Approach"", ""value"": ""Causal Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Data Analysis; Model Testing & Validation""}]","[{""description"": ""Understanding bias in hiring decisions through causal relationships."", ""goal"": ""Fairness""}]",,[]
77,Diversity Constraints in Recommendations,Incorporates diversity and fairness constraints in recommendation systems for varied and fair content exposure.,Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fairness-Constrained Optimisation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training; System Design and Implementation""}]","[{""description"": ""Ensuring fair representation of genres in music recommendation platforms."", ""goal"": ""Fairness""}]",,[]
78,Bayesian Fairness Regularisation,"Applies Bayesian methods to include fairness as a prior, allowing probabilistic interpretation of fairness constraints.",Model-Specific,Fairness,"[{""goal"": ""Fairness"", ""category"": ""In-Processing Techniques""}]","[{""category"": ""In-Processing Techniques"", ""subcategory"": ""Fairness-Constrained Optimisation""}]","[{""type"": ""Fairness Approach"", ""value"": ""Group Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Selection & Training""}]","[{""description"": ""Applying fairness regularisation in Bayesian models for credit risk assessment."", ""goal"": ""Fairness""}]",,[]
79,SHAP Values for Fairness,"Uses SHAP (SHapley Additive exPlanations) to attribute model predictions to input features, helping to identify bias contributions.",Model-Agnostic,Fairness,"[{""goal"": ""Fairness"", ""category"": ""Interpretability and Explainability""}]","[{""category"": ""Interpretability and Explainability"", ""subcategory"": ""Feature Attribution Methods""}]","[{""type"": ""Fairness Approach"", ""value"": ""Individual Fairness""}, {""type"": ""Project Lifecycle Stage"", ""value"": ""Model Testing & Validation; Model Documentation""}]","[{""description"": ""Explaining biased predictions in loan approvals by examining feature contributions."", ""goal"": ""Fairness""}]",,[]
