{
  "search_id": "20250930_161824_a9850782",
  "technique": {
    "slug": "local-interpretable-model-agnostic-explanations",
    "name": "Local Interpretable Model-Agnostic Explanations",
    "description": "LIME (Local Interpretable Model-agnostic Explanations) explains individual predictions by approximating the complex model's behaviour in a small neighbourhood around a specific instance. It works by creating perturbed versions of the input (e.g., removing words from text, changing pixel values in images, or varying feature values), obtaining the model's predictions for these variations, and training a simple interpretable model (typically linear regression) weighted by proximity to the original instance. The coefficients of this local surrogate model reveal which features most influenced the specific prediction."
  },
  "timestamp": "2025-09-30T16:18:24.000000",
  "selection_summary": {
    "candidates_evaluated": 29,
    "resources_selected": 5,
    "type_distribution": {
      "documentation": 1,
      "tutorial": 1,
      "tool": 1,
      "paper": 2
    }
  },
  "resources": [
    {
      "title": "Local Interpretable Model-Agnostic Explanations (lime) — lime 0.1 documentation",
      "url": "https://lime-ml.readthedocs.io/",
      "type": "documentation",
      "relevance_score": 0.98,
      "description": "Official documentation for the LIME Python package, providing comprehensive API reference and implementation guidance for practitioners."
    },
    {
      "title": "thomasp85/lime",
      "url": "https://github.com/thomasp85/lime",
      "type": "tool",
      "relevance_score": 0.95,
      "description": "Official R implementation of LIME with 489 stars, enabling LIME explanations for R users and integrating with caret models."
    },
    {
      "title": "Tutorials for eXplainable Artificial Intelligence (XAI) methods — XAI Tutorials",
      "url": "https://xai-tutorials.readthedocs.io/",
      "type": "tutorial",
      "relevance_score": 0.92,
      "description": "Comprehensive tutorial collection with Jupyter Notebooks and practical exercises covering LIME and other XAI methods for hands-on learning."
    },
    {
      "title": "Deterministic Local Interpretable Model-Agnostic Explanations for Stable Explainability",
      "url": "https://www.semanticscholar.org/paper/ee5775e16b00c2a150119c0cb6a4de8c29b30cd3",
      "type": "paper",
      "relevance_score": 0.90,
      "description": "Highly cited paper (227 citations) addressing LIME's key limitation of instability by proposing a deterministic variant that produces consistent explanations."
    },
    {
      "title": "DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations Approach for Computer-Aided Diagnosis Systems",
      "url": "https://www.semanticscholar.org/paper/e5c703aba8af983c36fedf08c32a6978eadd91b9",
      "type": "paper",
      "relevance_score": 0.88,
      "description": "Influential paper (163 citations) demonstrating DLIME for medical diagnosis, showing practical application in high-stakes healthcare decision-making."
    }
  ]
}