{
  "tag": {
    "name": "lifecycle-stage/model-optimization",
    "slug": "lifecycle-stage-model-optimization",
    "count": 2,
    "category": "lifecycle-stage"
  },
  "techniques": [
    {
      "slug": "model-pruning",
      "name": "Model Pruning",
      "description": "Model pruning systematically removes less important weights, neurons, or entire layers from neural networks to create smaller, more efficient models whilst maintaining performance. This process involves iterative removal based on importance criteria (weight magnitudes, gradient information, activation patterns) followed by fine-tuning. Pruning can be structured (removing entire neurons/channels) or unstructured (removing individual weights), with structured pruning providing greater computational benefits and interpretability through simplified architectures.",
      "assurance_goals": [
        "Explainability",
        "Reliability",
        "Safety"
      ],
      "tags": [
        "applicable-models/neural-network",
        "assurance-goal-category/explainability",
        "assurance-goal-category/explainability/model-simplification/pruning",
        "assurance-goal-category/explainability/explains/internal-mechanisms",
        "assurance-goal-category/explainability/explains/feature-importance",
        "assurance-goal-category/explainability/property/sparsity",
        "assurance-goal-category/explainability/property/comprehensibility",
        "assurance-goal-category/reliability",
        "assurance-goal-category/safety",
        "data-requirements/access-to-model-internals",
        "data-type/any",
        "evidence-type/quantitative-metric",
        "expertise-needed/ml-engineering",
        "lifecycle-stage/model-development",
        "lifecycle-stage/model-optimization",
        "technique-type/algorithmic"
      ],
      "example_use_cases": [
        {
          "description": "Compressing a medical imaging model from 100MB to 15MB for deployment on edge devices in remote clinics, enabling healthcare professionals to audit the remaining critical feature detectors and understand which anatomical patterns drive diagnoses whilst maintaining diagnostic accuracy.",
          "goal": "Explainability"
        },
        {
          "description": "Pruning a financial fraud detection model by 70% to eliminate redundant pathways that amplify noise, creating a more robust system that maintains consistent predictions across different transaction types and reduces false positives during market volatility.",
          "goal": "Reliability"
        },
        {
          "description": "Reducing an autonomous vehicle perception model to ensure predictable inference times under 50ms for safety-critical decisions, removing non-essential neurons to guarantee consistent computational behaviour whilst maintaining object detection accuracy for pedestrian safety.",
          "goal": "Safety"
        }
      ],
      "limitations": [
        {
          "description": "Determining optimal pruning ratios requires extensive experimentation as over-pruning can cause dramatic accuracy degradation, whilst under-pruning provides minimal benefits, making the process time-consuming and resource-intensive."
        },
        {
          "description": "Structured pruning often requires specific hardware or software framework support to realise computational benefits, limiting deployment flexibility and potentially necessitating model architecture changes."
        },
        {
          "description": "Pruned models may exhibit reduced robustness to out-of-distribution inputs or adversarial attacks, as removing neurons can eliminate defensive redundancy that helped handle edge cases."
        },
        {
          "description": "The iterative pruning and fine-tuning process can be computationally expensive, sometimes requiring more resources than training the original model, particularly for large-scale networks."
        },
        {
          "description": "Pruning criteria based on weight magnitudes or gradients may not align with interpretability goals, potentially removing neurons that contribute to model transparency whilst retaining complex, opaque pathways."
        }
      ],
      "resources": [
        {
          "title": "horseee/LLM-Pruner",
          "url": "https://github.com/horseee/LLM-Pruner",
          "source_type": "software_package",
          "description": "Structural pruning tool for large language models supporting Llama, BLOOM, and other LLMs with three-stage compression process requiring only 50,000 training samples for post-training recovery."
        },
        {
          "title": "Pruning Quickstart — Neural Network Intelligence",
          "url": "https://nni.readthedocs.io/en/stable/tutorials/pruning_quick_start.html",
          "source_type": "tutorial",
          "description": "Step-by-step tutorial for implementing model pruning using Microsoft's NNI toolkit, covering basic usage, pruning algorithms, and practical examples for neural network compression."
        },
        {
          "title": "Overview of NNI Model Pruning — Neural Network Intelligence",
          "url": "https://nni.readthedocs.io/en/stable/compression/pruning.html",
          "source_type": "documentation",
          "description": "Comprehensive documentation for NNI's pruning capabilities covering structured and unstructured pruning strategies, supported algorithms, and integration with popular deep learning frameworks."
        },
        {
          "title": "coldlarry/YOLOv3-complete-pruning",
          "url": "https://github.com/coldlarry/YOLOv3-complete-pruning",
          "source_type": "software_package",
          "description": "Complete pruning implementation for YOLOv3 object detection models demonstrating computer vision model compression with minimal accuracy loss for real-time inference applications."
        }
      ],
      "complexity_rating": 3,
      "computational_cost_rating": 2,
      "related_techniques": [
        "model-distillation"
      ]
    },
    {
      "slug": "meta-fair-classifier",
      "name": "Meta Fair Classifier",
      "description": "An in-processing fairness technique that employs meta-learning to modify any existing classifier for optimising fairness metrics whilst maintaining predictive performance. The method learns how to adjust model parameters or decision boundaries to satisfy fairness constraints such as demographic parity or equalised odds through iterative optimisation. This approach is particularly valuable when retrofitting fairness to pre-trained models that perform well but exhibit bias, as it can incorporate fairness without requiring complete retraining from scratch.",
      "assurance_goals": [
        "Fairness",
        "Transparency",
        "Reliability"
      ],
      "tags": [
        "applicable-models/agnostic",
        "assurance-goal-category/fairness",
        "assurance-goal-category/fairness/group",
        "assurance-goal-category/transparency",
        "assurance-goal-category/reliability",
        "data-requirements/sensitive-attributes",
        "data-requirements/labelled-data",
        "data-type/any",
        "evidence-type/quantitative-metric",
        "evidence-type/fairness-metric",
        "expertise-needed/ml-engineering",
        "expertise-needed/statistics",
        "fairness-approach/group",
        "lifecycle-stage/model-development",
        "lifecycle-stage/model-development/training",
        "lifecycle-stage/model-optimization",
        "technique-type/algorithmic"
      ],
      "example_use_cases": [
        {
          "description": "Retrofitting an existing hiring algorithm to achieve demographic parity across gender and ethnicity groups by using meta-learning to adjust decision boundaries, ensuring equitable candidate selection whilst maintaining the model's ability to identify qualified applicants.",
          "goal": "Fairness"
        },
        {
          "description": "Modifying a pre-trained credit scoring model to provide transparent fairness guarantees by learning optimal parameter adjustments that satisfy equalised odds constraints, enabling clear reporting on fair lending compliance to regulatory authorities.",
          "goal": "Transparency"
        },
        {
          "description": "Adapting a medical diagnosis model to ensure reliable performance across patient demographics by meta-learning fairness-aware adjustments that maintain diagnostic accuracy whilst reducing disparities in treatment recommendations across age and socioeconomic groups.",
          "goal": "Reliability"
        }
      ],
      "limitations": [
        {
          "description": "Meta-learning approach can be complex to implement, requiring expertise in both the underlying classifier and meta-optimisation techniques."
        },
        {
          "description": "Requires extensive hyperparameter tuning to balance fairness constraints with predictive performance, making optimisation challenging."
        },
        {
          "description": "May result in longer training times compared to simpler fairness techniques due to the iterative meta-learning process."
        },
        {
          "description": "Performance depends heavily on the quality and characteristics of the base classifier being modified, limiting effectiveness with poorly-performing models."
        },
        {
          "description": "Theoretical guarantees about fairness-accuracy trade-offs may not hold in practice due to finite sample effects and optimisation challenges."
        }
      ],
      "resources": [
        {
          "title": "ρ-Fair Method — holisticai documentation",
          "url": "https://holisticai.readthedocs.io/en/latest/getting_started/bias/mitigation/inprocessing/bc_meta_fair_classifier_rho_fair.html",
          "source_type": "documentation"
        },
        {
          "title": "aif360.algorithms.inprocessing — aif360 0.1.0 documentation",
          "url": "https://aif360.readthedocs.io/en/v0.2.3/modules/inprocessing.html",
          "source_type": "documentation"
        },
        {
          "title": "Welcome to AI Fairness 360's documentation! — aif360 0.1.0 ...",
          "url": "https://aif360.readthedocs.io/en/v0.2.3/",
          "source_type": "documentation"
        },
        {
          "title": "Algorithmic decision making methods for fair credit scoring",
          "url": "http://arxiv.org/abs/2209.07912",
          "source_type": "technical_paper",
          "authors": [
            "Moldovan, Darie"
          ],
          "publication_date": "2022-09-16"
        },
        {
          "title": "The Importance of Modeling Data Missingness in Algorithmic Fairness: A\n  Causal Perspective",
          "url": "http://arxiv.org/abs/2012.11448",
          "source_type": "technical_paper",
          "authors": [
            "Amayuelas, Alfonso",
            "Deshpande, Amit",
            "Goel, Naman",
            "Sharma, Amit"
          ],
          "publication_date": "2020-12-21"
        }
      ],
      "complexity_rating": 5,
      "computational_cost_rating": 4,
      "related_techniques": [
        "adversarial-debiasing",
        "fair-adversarial-networks",
        "prejudice-remover-regulariser",
        "exponentiated-gradient-reduction",
        "fair-transfer-learning",
        "adaptive-sensitive-reweighting",
        "multi-accuracy-boosting"
      ]
    }
  ],
  "count": 2
}