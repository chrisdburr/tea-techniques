{
  "tag": {
    "name": "lifecycle-stage/data-handling",
    "slug": "lifecycle-stage-data-handling",
    "count": 4,
    "category": "lifecycle-stage"
  },
  "techniques": [
    {
      "slug": "synthetic-data-generation",
      "name": "Synthetic Data Generation",
      "description": "Synthetic data generation creates artificial datasets that aim to preserve the statistical properties, distributions, and relationships of real data whilst containing no actual records from real individuals. The technique encompasses various approaches including generative adversarial networks (GANs), variational autoencoders (VAEs), statistical sampling methods, and privacy-preserving techniques like differential privacy. Beyond privacy protection, synthetic data serves multiple purposes: augmenting limited datasets, balancing class distributions, testing model robustness, enabling data sharing across organisations, and supporting fairness assessments by generating representative samples for underrepresented groups.",
      "assurance_goals": [
        "Privacy",
        "Fairness",
        "Reliability",
        "Safety"
      ],
      "tags": [
        "applicable-models/architecture/neural-networks/generative/gan",
        "applicable-models/architecture/neural-networks/generative/vae",
        "applicable-models/architecture/probabilistic",
        "applicable-models/paradigm/generative",
        "applicable-models/paradigm/unsupervised",
        "applicable-models/requirements/training-data",
        "applicable-models/requirements/white-box",
        "assurance-goal-category/fairness",
        "assurance-goal-category/privacy",
        "assurance-goal-category/reliability",
        "assurance-goal-category/safety",
        "data-requirements/no-special-requirements",
        "data-type/any",
        "evidence-type/structured-output",
        "expertise-needed/cryptography",
        "expertise-needed/ml-engineering",
        "expertise-needed/statistics",
        "lifecycle-stage/data-handling",
        "lifecycle-stage/model-development",
        "technique-type/algorithmic"
      ],
      "example_use_cases": [
        {
          "description": "Creating realistic but synthetic electronic health records for developing and testing medical diagnosis algorithms without exposing real patient data, enabling secure collaboration between healthcare institutions.",
          "goal": "Privacy"
        },
        {
          "description": "Generating synthetic samples for underrepresented demographic groups in a hiring dataset to train fair recruitment models, ensuring all groups have sufficient representation for bias testing and mitigation.",
          "goal": "Fairness"
        },
        {
          "description": "Augmenting limited training data for rare medical conditions by generating synthetic patient records, improving model reliability and performance on edge cases where real data is insufficient.",
          "goal": "Reliability"
        },
        {
          "description": "Creating synthetic financial transaction data for testing fraud detection systems in development environments, avoiding exposure of real customer financial information whilst maintaining realistic attack patterns.",
          "goal": "Safety"
        }
      ],
      "limitations": [
        {
          "description": "May not capture all subtle patterns, correlations, and edge cases present in real data, potentially leading to reduced model performance when deployed on actual data with different characteristics."
        },
        {
          "description": "Generating high-quality synthetic data that maintains both statistical fidelity and utility requires sophisticated techniques and substantial computational resources, especially for complex, high-dimensional datasets."
        },
        {
          "description": "Privacy-preserving approaches may still risk information leakage through statistical inference attacks, membership inference, or model inversion, requiring careful privacy budget management and validation."
        },
        {
          "description": "Synthetic data may inadvertently amplify existing biases in the original data or introduce new biases through the generation process, particularly in generative models trained on biased datasets."
        },
        {
          "description": "Validation and quality assessment of synthetic data is challenging, as traditional metrics may not adequately capture whether the synthetic data preserves the relationships and patterns needed for specific downstream tasks."
        }
      ],
      "resources": [
        {
          "title": "sdv-dev/SDV",
          "url": "https://github.com/sdv-dev/SDV",
          "source_type": "software_package"
        },
        {
          "title": "An evaluation framework for synthetic data generation models",
          "url": "http://arxiv.org/pdf/2404.08866v1",
          "source_type": "technical_paper",
          "authors": [
            "Ioannis E. Livieris",
            "Nikos Alimpertis",
            "George Domalis",
            "Dimitris Tsakalidis"
          ],
          "publication_date": "2024-04-13"
        },
        {
          "title": "Synthetic Data — SecureML 0.2.2 documentation",
          "url": "https://secureml.readthedocs.io/en/latest/user_guide/synthetic_data.html",
          "source_type": "documentation"
        },
        {
          "title": "How to Generate Real-World Synthetic Data with CTGAN | Towards ...",
          "url": "https://towardsdatascience.com/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde/",
          "source_type": "tutorial"
        }
      ],
      "complexity_rating": 4,
      "computational_cost_rating": 4,
      "related_techniques": [
        "federated-learning",
        "differential-privacy",
        "homomorphic-encryption"
      ]
    },
    {
      "slug": "differential-privacy",
      "name": "Differential Privacy",
      "description": "Differential privacy provides mathematically rigorous privacy protection by adding carefully calibrated random noise to data queries, statistical computations, or machine learning outputs. The technique works by ensuring that the presence or absence of any individual's data has minimal impact on the results - specifically, any query result should be nearly indistinguishable whether or not a particular person's data is included. This is achieved through controlled noise addition that scales with the query's sensitivity and a privacy budget (epsilon) that quantifies the privacy-utility trade-off. The smaller the epsilon, the more noise is added and the stronger the privacy guarantee, but at the cost of reduced accuracy.",
      "assurance_goals": [
        "Privacy",
        "Transparency",
        "Fairness"
      ],
      "tags": [
        "applicable-models/architecture/model-agnostic",
        "applicable-models/requirements/black-box",
        "assurance-goal-category/fairness",
        "assurance-goal-category/privacy",
        "assurance-goal-category/privacy/formal-guarantee/differential-privacy",
        "assurance-goal-category/transparency",
        "data-requirements/no-special-requirements",
        "data-type/any",
        "evidence-type/privacy-guarantee",
        "evidence-type/quantitative-metric",
        "expertise-needed/cryptography",
        "expertise-needed/ml-engineering",
        "expertise-needed/statistics",
        "lifecycle-stage/data-handling",
        "lifecycle-stage/model-development",
        "lifecycle-stage/system-deployment-and-use",
        "technique-type/algorithmic"
      ],
      "example_use_cases": [
        {
          "description": "Protecting individual privacy in census data analysis by adding calibrated noise to demographic statistics, ensuring households cannot be re-identified whilst maintaining accurate population insights for policy planning.",
          "goal": "Privacy"
        },
        {
          "description": "Publishing differentially private aggregate statistics about model performance across different demographic groups, enabling transparent bias auditing without exposing sensitive individual prediction details or group membership.",
          "goal": "Transparency"
        },
        {
          "description": "Enabling fair evaluation of lending algorithms by releasing differentially private performance metrics across protected groups, allowing regulatory compliance checking whilst protecting individual applicant privacy.",
          "goal": "Fairness"
        }
      ],
      "limitations": [
        {
          "description": "Adding noise inherently reduces the accuracy and utility of results, with stronger privacy guarantees (smaller epsilon values) leading to more significant degradation in data quality."
        },
        {
          "description": "Setting the privacy budget (epsilon) requires expertise and careful consideration of the privacy-utility trade-off, with no universal guidelines for appropriate values across different applications."
        },
        {
          "description": "Sequential queries consume the privacy budget cumulatively, potentially requiring careful query planning and potentially prohibiting future analyses once the budget is exhausted."
        },
        {
          "description": "Implementation complexity is high, requiring deep understanding of sensitivity analysis, noise mechanisms, and composition theorems to avoid inadvertent privacy violations."
        },
        {
          "description": "May not protect against all privacy attacks, particularly sophisticated adversaries with auxiliary information or when combined with other data sources that could aid re-identification."
        }
      ],
      "resources": [
        {
          "title": "Google Differential Privacy Library",
          "url": "https://github.com/google/differential-privacy",
          "source_type": "software_package",
          "description": "Open-source library providing implementations of differential privacy algorithms and utilities"
        },
        {
          "title": "The Algorithmic Foundations of Differential Privacy",
          "url": "https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf",
          "source_type": "technical_paper",
          "authors": [
            "Cynthia Dwork",
            "Aaron Roth"
          ],
          "description": "Foundational monograph on differential privacy theory and algorithms"
        },
        {
          "title": "Opacus: User-Friendly Differential Privacy Library in PyTorch",
          "url": "https://github.com/pytorch/opacus",
          "source_type": "software_package",
          "description": "PyTorch library for training neural networks with differential privacy"
        },
        {
          "title": "Programming Differential Privacy",
          "url": "https://programming-dp.com/",
          "source_type": "tutorial",
          "description": "Comprehensive online book and tutorial for learning differential privacy programming"
        }
      ],
      "complexity_rating": 5,
      "computational_cost_rating": 3,
      "related_techniques": [
        "synthetic-data-generation",
        "federated-learning",
        "homomorphic-encryption"
      ]
    },
    {
      "slug": "datasheets-for-datasets",
      "name": "Datasheets for Datasets",
      "description": "Datasheets for datasets establish comprehensive documentation standards for datasets, systematically recording creation methodology, data composition, collection procedures, preprocessing transformations, intended applications, potential biases, privacy considerations, and maintenance protocols. These structured documents enhance dataset transparency by providing essential context for appropriate usage, enabling informed decisions about dataset suitability for specific tasks, supporting bias detection and mitigation efforts, ensuring compliance with data protection regulations, and promoting responsible data stewardship throughout the entire data lifecycle from collection to disposal.",
      "assurance_goals": [
        "Transparency",
        "Fairness",
        "Privacy"
      ],
      "tags": [
        "applicable-models/architecture/model-agnostic",
        "applicable-models/requirements/black-box",
        "assurance-goal-category/fairness",
        "assurance-goal-category/privacy",
        "assurance-goal-category/transparency",
        "data-requirements/no-special-requirements",
        "data-type/any",
        "evidence-type/documentation",
        "expertise-needed/domain-knowledge",
        "expertise-needed/regulatory-compliance",
        "lifecycle-stage/data-handling",
        "lifecycle-stage/data-handling/collection",
        "lifecycle-stage/data-handling/preparation",
        "technique-type/documentation"
      ],
      "example_use_cases": [
        {
          "description": "Documenting a medical imaging dataset with detailed information about patient privacy protections, anonymisation procedures, and data sharing constraints to ensure sensitive health information is handled appropriately and regulatory compliance is maintained.",
          "goal": "Privacy"
        },
        {
          "description": "Creating comprehensive datasheets for recruitment datasets that document demographic representation across different job categories, helping developers identify potential bias in training data and develop more equitable hiring algorithms.",
          "goal": "Fairness"
        },
        {
          "description": "Establishing transparent documentation for financial transaction datasets that clearly describes data collection methodology, preprocessing steps, and intended use cases, enabling researchers to make informed decisions about dataset appropriateness for their specific applications.",
          "goal": "Transparency"
        }
      ],
      "limitations": [
        {
          "description": "Creating thorough datasheets requires significant time investment and domain expertise to properly document collection methods, biases, and ethical considerations, potentially delaying dataset release or publication."
        },
        {
          "description": "Information may become outdated as datasets undergo preprocessing, cleaning, or augmentation, requiring ongoing maintenance to ensure documentation accuracy throughout the data lifecycle."
        },
        {
          "description": "Absence of standardised templates and enforcement mechanisms leads to inconsistent documentation quality and completeness across different organisations and research communities."
        },
        {
          "description": "Dataset creators may intentionally omit sensitive information about collection methods, participant consent, or potential biases to avoid legal liability or competitive disadvantage."
        },
        {
          "description": "Limited adoption and awareness means many existing datasets lack proper documentation, creating gaps in the historical record and making legacy dataset assessment difficult."
        }
      ],
      "resources": [
        {
          "title": "Datasheets for Datasets",
          "url": "https://arxiv.org/abs/1803.09010",
          "source_type": "technical_paper",
          "authors": [
            "Timnit Gebru",
            "Jamie Morgenstern",
            "Briana Vecchione",
            "Jennifer Wortman Vaughan",
            "Hanna Wallach",
            "Hal Daumé III",
            "Kate Crawford"
          ],
          "publication_date": "2018-03-23",
          "description": "Foundational paper proposing standardised documentation for machine learning datasets to facilitate transparency, accountability, and better communication between dataset creators and consumers"
        },
        {
          "title": "Datasheets for AI and medical datasets (DAIMS): a data validation and documentation framework before machine learning analysis in medical research",
          "url": "http://arxiv.org/pdf/2501.14094v1",
          "source_type": "technical_paper",
          "authors": [
            "Ramtin Zargari Marandi",
            "Anne Svane Frahm",
            "Maja Milojevic"
          ],
          "publication_date": "2025-01-23",
          "description": "Recent framework extending datasheets specifically for medical AI datasets, providing validation and documentation standards for healthcare machine learning research"
        },
        {
          "title": "MT-Adapted Datasheets for Datasets: Template and Repository",
          "url": "http://arxiv.org/pdf/2005.13156v1",
          "source_type": "technical_paper",
          "authors": [
            "Marta R. Costa-jussà",
            "Roger Creus",
            "Oriol Domingo",
            "Albert Domínguez",
            "Miquel Escobar",
            "Cayetana López",
            "Marina Garcia",
            "Margarita Geleta"
          ],
          "publication_date": "2020-05-27"
        },
        {
          "title": "Understanding Machine Learning Practitioners' Data Documentation Perceptions, Needs, Challenges, and Desiderata",
          "url": "http://arxiv.org/pdf/2206.02923v2",
          "source_type": "technical_paper",
          "authors": [
            "Amy K. Heger",
            "Liz B. Marquis",
            "Mihaela Vorvoreanu",
            "Hanna Wallach",
            "Jennifer Wortman Vaughan"
          ],
          "publication_date": "2022-06-06"
        }
      ],
      "complexity_rating": 2,
      "computational_cost_rating": 1,
      "related_techniques": [
        "model-cards",
        "mlflow-experiment-tracking",
        "data-version-control",
        "automated-documentation-generation"
      ]
    },
    {
      "slug": "data-version-control",
      "name": "Data Version Control",
      "description": "Data Version Control (DVC) is a Git-like version control system specifically designed for machine learning data, models, and experiments. It tracks changes to large data files, maintains reproducible ML pipelines, and creates a complete audit trail of data transformations, model training, and evaluation processes. DVC works alongside Git to provide end-to-end lineage tracking from raw data through preprocessing, training, and deployment, enabling teams to reproduce any model version and understand exactly how datasets evolved throughout the ML lifecycle.",
      "assurance_goals": [
        "Transparency",
        "Reliability"
      ],
      "tags": [
        "applicable-models/architecture/model-agnostic",
        "applicable-models/requirements/black-box",
        "assurance-goal-category/reliability",
        "assurance-goal-category/transparency",
        "data-requirements/no-special-requirements",
        "data-type/any",
        "evidence-type/documentation",
        "expertise-needed/ml-engineering",
        "expertise-needed/software-engineering",
        "lifecycle-stage/data-handling",
        "lifecycle-stage/model-development",
        "lifecycle-stage/system-deployment-and-use",
        "technique-type/process"
      ],
      "example_use_cases": [
        {
          "description": "Tracking medical imaging dataset versions and model training pipelines to ensure reproducible research results, enabling hospitals to verify which specific data version and preprocessing steps were used for regulatory submissions.",
          "goal": "Transparency"
        },
        {
          "description": "Managing credit scoring model data pipelines with complete version control of training datasets, feature engineering steps, and model artifacts, ensuring reliable model reproduction and rollback capabilities when performance issues arise.",
          "goal": "Reliability"
        },
        {
          "description": "Maintaining pharmaceutical drug discovery data lineage across multiple research teams, tracking compound datasets, feature extraction processes, and model versions to support FDA submissions with complete experimental provenance.",
          "goal": "Transparency"
        }
      ],
      "limitations": [
        {
          "description": "Requires learning Git-like workflows and CLI commands, which may have a steep learning curve for teams unfamiliar with version control systems."
        },
        {
          "description": "Storage costs can be substantial for large datasets with frequent changes, especially when maintaining multiple versions and branches of data."
        },
        {
          "description": "Complex data pipelines with many interdependencies may require significant setup time and careful configuration to track properly."
        },
        {
          "description": "Performance can degrade with very large files or datasets due to checksumming and synchronisation overhead during operations."
        },
        {
          "description": "Team coordination becomes essential as improper branch management or merge conflicts can disrupt collaborative workflows."
        }
      ],
      "resources": [
        {
          "title": "DVC Documentation",
          "url": "https://dvc.org/doc",
          "source_type": "documentation",
          "description": "Comprehensive official documentation covering DVC installation, data versioning, pipeline creation, and collaborative workflows with tutorials and best practices"
        },
        {
          "title": "iterative/dvc",
          "url": "https://github.com/iterative/dvc",
          "source_type": "software_package",
          "description": "Official DVC open-source repository containing the complete data version control system for machine learning with Git integration"
        },
        {
          "title": "DVC Tutorial - Data Version Control for Machine Learning",
          "url": "https://dvc.org/doc/start",
          "source_type": "tutorial",
          "description": "Step-by-step getting started guide demonstrating DVC basics including data tracking, pipeline creation, and experiment management"
        }
      ],
      "complexity_rating": 3,
      "computational_cost_rating": 2,
      "acronym": "DVC",
      "related_techniques": [
        "model-cards",
        "datasheets-for-datasets",
        "mlflow-experiment-tracking",
        "automated-documentation-generation"
      ]
    }
  ],
  "count": 4
}