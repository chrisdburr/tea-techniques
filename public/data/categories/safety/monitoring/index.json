{
  "goal": "safety",
  "dimension": "monitoring",
  "subcategories": [
    "anomaly-detection"
  ],
  "techniques": [
    {
      "slug": "anomaly-detection",
      "name": "Anomaly Detection",
      "description": "Anomaly detection identifies unusual behaviours, inputs, or outputs that deviate significantly from established normal patterns using statistical, machine learning, or rule-based methods. Applied to AI/ML systems, it serves as a continuous monitoring mechanism that can flag unexpected model predictions, suspicious input patterns, data drift, adversarial attacks, or operational malfunctions. By establishing baselines of normal system behaviour and alerting when deviations exceed predefined thresholds, organisations can detect potential security threats, model degradation, fairness violations, or system failures before they cause significant harm.",
      "assurance_goals": [
        "Safety",
        "Reliability",
        "Fairness",
        "Security"
      ],
      "tags": [
        "applicable-models/agnostic",
        "assurance-goal-category/safety",
        "assurance-goal-category/safety/monitoring/anomaly-detection",
        "assurance-goal-category/reliability",
        "assurance-goal-category/fairness",
        "data-requirements/no-special-requirements",
        "data-type/any",
        "evidence-type/quantitative-metric",
        "expertise-needed/statistics",
        "expertise-needed/ml-engineering",
        "lifecycle-stage/system-deployment-and-use",
        "lifecycle-stage/system-deployment-and-use/monitoring",
        "technique-type/algorithmic"
      ],
      "example_use_cases": [
        {
          "description": "Monitoring a content moderation AI system to detect when it starts flagging significantly more or fewer posts than usual, which could indicate model drift, adversarial attacks, or changes in user behaviour patterns that require immediate investigation to prevent harmful content from appearing.",
          "goal": "Safety"
        },
        {
          "description": "Implementing anomaly detection on a medical diagnosis AI to identify when prediction confidence scores or feature importance patterns deviate from historical norms, helping catch model degradation or data quality issues that could lead to misdiagnoses before patients are affected.",
          "goal": "Reliability"
        },
        {
          "description": "Deploying anomaly detection on a hiring algorithm to monitor for unusual patterns in how candidates from different demographic groups are scored or rejected, enabling early detection of emerging bias issues or attempts to game the system through demographic manipulation.",
          "goal": "Fairness"
        }
      ],
      "limitations": [
        {
          "description": "Setting appropriate sensitivity thresholds is challenging and requires domain expertise, as overly sensitive settings generate excessive false alarms whilst conservative settings may miss genuine anomalies."
        },
        {
          "description": "May generate false positives for legitimate edge cases or rare but valid system behaviours, potentially causing unnecessary alerts and disrupting normal operations."
        },
        {
          "description": "Limited effectiveness against novel or sophisticated attacks that deliberately mimic normal patterns or gradually shift behaviour to avoid detection thresholds."
        },
        {
          "description": "Requires substantial historical data to establish reliable baselines of normal behaviour, and may struggle with systems that have naturally high variability or seasonal patterns."
        },
        {
          "description": "Detection lag can occur between when an anomaly begins and when it exceeds detection thresholds, potentially allowing harmful behaviour to persist during the detection window."
        }
      ],
      "resources": [
        {
          "title": "Anomaly Detection Toolkit (ADTK)",
          "url": "https://adtk.readthedocs.io/en/stable/",
          "source_type": "software_package",
          "description": "Python library for unsupervised and rule-based time series anomaly detection with unified APIs, flexible algorithm combination, and support for feature engineering and ensemble methods"
        },
        {
          "title": "TimeEval: Time Series Anomaly Detection Evaluation Framework",
          "url": "https://timeeval.readthedocs.io/",
          "source_type": "software_package",
          "description": "Comprehensive evaluation tool for comparing time series anomaly detection algorithms across multiple datasets with standardized metrics and distributed execution support"
        },
        {
          "title": "DeepOD: Deep Learning for Outlier Detection",
          "url": "https://deepod.readthedocs.io/",
          "source_type": "software_package",
          "description": "Python library featuring 27 deep learning algorithms for tabular and time-series anomaly detection with unified APIs and diverse network architectures including LSTM, GRU, TCN, and Transformer"
        },
        {
          "title": "A Beginner's Guide to Anomaly Detection Techniques in Data Science",
          "url": "https://www.kdnuggets.com/2023/05/beginner-guide-anomaly-detection-techniques-data-science.html",
          "source_type": "tutorial",
          "description": "Beginner-friendly introduction covering Isolation Forest, Local Outlier Factor, and Autoencoder techniques with explanations of point, contextual, and collective anomaly types"
        }
      ],
      "complexity_rating": 3,
      "computational_cost_rating": 3,
      "related_techniques": [
        "out-of-distribution-detector-for-neural-networks"
      ]
    },
    {
      "slug": "runtime-monitoring-and-circuit-breakers",
      "name": "Runtime Monitoring and Circuit Breakers",
      "description": "Runtime monitoring and circuit breakers establish continuous surveillance of AI/ML systems in production, tracking critical metrics such as prediction accuracy, response times, input characteristics, output distributions, and system resource usage. When monitored parameters exceed predefined safety thresholds or exhibit anomalous patterns, automated circuit breakers immediately trigger protective actions including request throttling, service degradation, system shutdown, or failover to backup mechanisms. This approach provides real-time defensive capabilities that prevent cascading failures, ensure consistent service reliability, and maintain transparent operation status for stakeholders monitoring system health.",
      "assurance_goals": [
        "Safety",
        "Reliability",
        "Transparency"
      ],
      "tags": [
        "applicable-models/agnostic",
        "assurance-goal-category/safety",
        "assurance-goal-category/safety/monitoring/anomaly-detection",
        "assurance-goal-category/reliability",
        "assurance-goal-category/transparency",
        "data-requirements/no-special-requirements",
        "data-type/any",
        "evidence-type/quantitative-metric",
        "expertise-needed/software-engineering",
        "expertise-needed/ml-engineering",
        "lifecycle-stage/system-deployment-and-use",
        "lifecycle-stage/system-deployment-and-use/monitoring",
        "technique-type/algorithmic"
      ],
      "example_use_cases": [
        {
          "description": "Implementing circuit breakers in a medical AI system that automatically halt diagnosis recommendations if prediction confidence drops below 85%, error rates exceed 2%, or response times increase beyond acceptable limits, preventing potentially harmful misdiagnoses during system degradation.",
          "goal": "Safety"
        },
        {
          "description": "Deploying runtime monitoring for a recommendation engine that tracks recommendation diversity, click-through rates, and user engagement patterns, automatically switching to simpler algorithms when complex models show signs of performance degradation or unusual behaviour patterns.",
          "goal": "Reliability"
        },
        {
          "description": "Establishing transparent monitoring dashboards for a loan approval system that display real-time metrics on approval rates across demographic groups, processing times, and model confidence levels, enabling stakeholders to verify consistent and fair operation.",
          "goal": "Transparency"
        }
      ],
      "limitations": [
        {
          "description": "Threshold calibration requires extensive domain expertise and historical data analysis, as overly sensitive settings trigger excessive false alarms whilst conservative thresholds may miss genuine system failures."
        },
        {
          "description": "False positive alerts can unnecessarily disrupt service availability and user experience, potentially causing more harm than the issues they aim to prevent, especially in time-sensitive applications."
        },
        {
          "description": "Sophisticated attacks or gradual performance degradation may operate within normal metric ranges, evading detection by staying below established thresholds whilst still causing cumulative damage."
        },
        {
          "description": "Monitoring infrastructure introduces additional complexity and potential failure points, requiring robust implementation to avoid situations where the monitoring system itself becomes a source of system instability."
        },
        {
          "description": "High-frequency monitoring and circuit breaker mechanisms can add computational overhead and latency to system operations, potentially impacting performance in resource-constrained environments."
        }
      ],
      "resources": [
        {
          "title": "aiobreaker: Python Circuit Breaker for Asyncio",
          "url": "https://github.com/arlyon/aiobreaker",
          "source_type": "software_package",
          "description": "Python library implementing the Circuit Breaker design pattern for asyncio applications, preventing system-wide failures by protecting integration points with configurable failure thresholds and reset timeouts"
        },
        {
          "title": "Improving Alignment and Robustness with Circuit Breakers",
          "url": "https://arxiv.org/html/2406.04313v4",
          "source_type": "technical_paper",
          "authors": [
            "Andy Zou"
          ],
          "description": "Research paper introducing circuit breakers for AI safety that directly interrupt harmful model representations during generation, significantly reducing attack success rates while maintaining model capabilities"
        }
      ],
      "complexity_rating": 3,
      "computational_cost_rating": 2,
      "related_techniques": [
        "internal-review-boards",
        "red-teaming",
        "human-in-the-loop-safeguards",
        "confidence-thresholding"
      ]
    }
  ],
  "count": 2
}