{
  "slug": "datasheets-for-datasets",
  "name": "Datasheets for Datasets",
  "description": "Datasheets for datasets establish comprehensive documentation standards for datasets, systematically recording creation methodology, data composition, collection procedures, preprocessing transformations, intended applications, potential biases, privacy considerations, and maintenance protocols. These structured documents enhance dataset transparency by providing essential context for appropriate usage, enabling informed decisions about dataset suitability for specific tasks, supporting bias detection and mitigation efforts, ensuring compliance with data protection regulations, and promoting responsible data stewardship throughout the entire data lifecycle from collection to disposal.",
  "assurance_goals": [
    "Transparency",
    "Fairness",
    "Privacy"
  ],
  "tags": [
    "applicable-models/architecture/model-agnostic",
    "applicable-models/requirements/black-box",
    "assurance-goal-category/fairness",
    "assurance-goal-category/privacy",
    "assurance-goal-category/transparency",
    "data-requirements/no-special-requirements",
    "data-type/any",
    "evidence-type/documentation",
    "expertise-needed/domain-knowledge",
    "expertise-needed/regulatory-compliance",
    "lifecycle-stage/data-handling",
    "lifecycle-stage/data-handling/collection",
    "lifecycle-stage/data-handling/preparation",
    "technique-type/documentation"
  ],
  "example_use_cases": [
    {
      "description": "Documenting a medical imaging dataset with detailed information about patient privacy protections, anonymisation procedures, and data sharing constraints to ensure sensitive health information is handled appropriately and regulatory compliance is maintained.",
      "goal": "Privacy"
    },
    {
      "description": "Creating comprehensive datasheets for recruitment datasets that document demographic representation across different job categories, helping developers identify potential bias in training data and develop more equitable hiring algorithms.",
      "goal": "Fairness"
    },
    {
      "description": "Establishing transparent documentation for financial transaction datasets that clearly describes data collection methodology, preprocessing steps, and intended use cases, enabling researchers to make informed decisions about dataset appropriateness for their specific applications.",
      "goal": "Transparency"
    }
  ],
  "limitations": [
    {
      "description": "Creating thorough datasheets requires significant time investment and domain expertise to properly document collection methods, biases, and ethical considerations, potentially delaying dataset release or publication."
    },
    {
      "description": "Information may become outdated as datasets undergo preprocessing, cleaning, or augmentation, requiring ongoing maintenance to ensure documentation accuracy throughout the data lifecycle."
    },
    {
      "description": "Absence of standardised templates and enforcement mechanisms leads to inconsistent documentation quality and completeness across different organisations and research communities."
    },
    {
      "description": "Dataset creators may intentionally omit sensitive information about collection methods, participant consent, or potential biases to avoid legal liability or competitive disadvantage."
    },
    {
      "description": "Limited adoption and awareness means many existing datasets lack proper documentation, creating gaps in the historical record and making legacy dataset assessment difficult."
    }
  ],
  "resources": [
    {
      "title": "Datasheets for Datasets",
      "url": "https://arxiv.org/abs/1803.09010",
      "source_type": "technical_paper",
      "authors": [
        "Timnit Gebru",
        "Jamie Morgenstern",
        "Briana Vecchione",
        "Jennifer Wortman Vaughan",
        "Hanna Wallach",
        "Hal Daumé III",
        "Kate Crawford"
      ],
      "publication_date": "2018-03-23",
      "description": "Foundational paper proposing standardised documentation for machine learning datasets to facilitate transparency, accountability, and better communication between dataset creators and consumers"
    },
    {
      "title": "Datasheets for AI and medical datasets (DAIMS): a data validation and documentation framework before machine learning analysis in medical research",
      "url": "http://arxiv.org/pdf/2501.14094v1",
      "source_type": "technical_paper",
      "authors": [
        "Ramtin Zargari Marandi",
        "Anne Svane Frahm",
        "Maja Milojevic"
      ],
      "publication_date": "2025-01-23",
      "description": "Recent framework extending datasheets specifically for medical AI datasets, providing validation and documentation standards for healthcare machine learning research"
    },
    {
      "title": "MT-Adapted Datasheets for Datasets: Template and Repository",
      "url": "http://arxiv.org/pdf/2005.13156v1",
      "source_type": "technical_paper",
      "authors": [
        "Marta R. Costa-jussà",
        "Roger Creus",
        "Oriol Domingo",
        "Albert Domínguez",
        "Miquel Escobar",
        "Cayetana López",
        "Marina Garcia",
        "Margarita Geleta"
      ],
      "publication_date": "2020-05-27"
    },
    {
      "title": "Understanding Machine Learning Practitioners' Data Documentation Perceptions, Needs, Challenges, and Desiderata",
      "url": "http://arxiv.org/pdf/2206.02923v2",
      "source_type": "technical_paper",
      "authors": [
        "Amy K. Heger",
        "Liz B. Marquis",
        "Mihaela Vorvoreanu",
        "Hanna Wallach",
        "Jennifer Wortman Vaughan"
      ],
      "publication_date": "2022-06-06"
    }
  ],
  "complexity_rating": 2,
  "computational_cost_rating": 1,
  "related_techniques": [
    "model-cards",
    "mlflow-experiment-tracking",
    "data-version-control",
    "automated-documentation-generation"
  ]
}