|**Technique Name**|**Description**|**Category**|**Sub-Category**|**Fairness Approach**|**Project Lifecycle Stage**|**Model Dependency**|**Example Use Case**|
|---|---|---|---|---|---|---|---|
|**Reweighing**|Assigns weights to instances in the training data to ensure different groups are equally represented in all labels.|Pre-Processing|Data Transformation|Group Fairness|Preprocessing and Feature Engineering|Model-Agnostic|Balancing gender representation in credit approval datasets before training a classifier.|
|**Disparate Impact Remover**|Edits feature values to reduce dependence between features and protected attributes, aiming to mitigate disparate impact.|Pre-Processing|Data Transformation|Group Fairness|Preprocessing and Feature Engineering|Model-Agnostic|Adjusting salary features to reduce gender bias in income prediction models.|
|**Learning Fair Representations**|Learns latent representations that encode data well but obfuscate information about protected attributes.|Pre-Processing|Fair Representation Learning|Group Fairness|Preprocessing and Feature Engineering|Model-Agnostic|Creating unbiased data representations for hiring algorithms.|
|**Fairness GAN**|Employs Generative Adversarial Networks to generate fair representations of data that obfuscate protected attributes.|Pre-Processing|Fair Representation Learning|Group Fairness|Preprocessing and Feature Engineering|Model-Specific|Creating unbiased datasets for training fair image recognition models.|
|**Optimised Pre-Processing**|Modifies training data features and labels to induce fairness while preserving data utility.|Pre-Processing|Data Transformation|Group Fairness|Preprocessing and Feature Engineering|Model-Agnostic|Adjusting criminal justice data to reduce racial bias before training models.|
|**Relabelling**|Changes labels of certain instances in training data to reduce bias, often based on fairness constraints.|Pre-Processing|Data Transformation|Group Fairness|Preprocessing and Feature Engineering|Model-Agnostic|Modifying labels in loan default datasets to mitigate historical biases.|
|**Preferential Sampling**|Re-samples data with preference for certain groups to achieve fair representation in training datasets.|Pre-Processing|Data Transformation|Group Fairness|Preprocessing and Feature Engineering|Model-Agnostic|Oversampling minority groups in medical data to train unbiased models.|
|**Fairness Through Unawareness**|Ensures the model does not use protected attributes in decisions; however, indirect bias may persist.|Pre-Processing|Data Transformation|Group Fairness|Preprocessing and Feature Engineering|Model-Agnostic|Removing gender as a feature in employee promotion predictions.|
|**Adversarial Debiasing**|Trains a model to make accurate predictions while reducing the ability of an adversary to predict protected attributes from outputs.|In-Processing|Adversarial Debiasing|Group Fairness|Model Selection & Training|Model-Specific|Developing fair classification models for loan approvals by reducing gender predictability.|
|**Adversarial Debiasing for Text**|Applies adversarial debiasing techniques specifically to textual data to mitigate biases in language models.|In-Processing|Adversarial Debiasing|Group Fairness|Model Selection & Training|Model-Specific|Reducing gender bias in sentiment analysis models by adversarial training on text data.|
|**Fair Adversarial Networks**|Extends adversarial debiasing by incorporating fairness into deep learning via adversarial training.|In-Processing|Adversarial Debiasing|Group Fairness|Model Selection & Training|Model-Specific|Reducing bias in facial recognition systems with adversarial networks.|
|**Prejudice Remover Regulariser**|Incorporates a fairness penalty into the learning objective to penalise models that encode biases with respect to protected attributes.|In-Processing|Fairness-Constrained Optimisation|Group Fairness|Model Selection & Training|Model-Specific|Training logistic regression models with fairness constraints for university admissions.|
|**Meta Fair Classifier**|Modifies any classifier to optimise for fairness metrics using a meta-learning algorithm.|In-Processing|Fairness-Constrained Optimisation|Group Fairness|Model Selection & Training|Model-Agnostic|Applying fairness optimisation to models in employee evaluation systems.|
|**Exponentiated Gradient Reduction**|Formulates fairness as a constrained optimisation problem, using exponentiated gradient methods to find optimal classifiers.|In-Processing|Fairness-Constrained Optimisation|Group Fairness|Model Selection & Training|Model-Agnostic|Training fair classifiers for employment screening processes.|
|**Fair Transfer Learning**|Adapts models trained on one domain to another while preserving fairness constraints across domains.|In-Processing|Fair Representation Learning|Group Fairness|Model Selection & Training|Model-Specific|Transferring fairness-aware models from one region's data to another in healthcare analytics.|
|**Adaptive Sensitive Reweighting**|Dynamically adjusts weights during training based on model performance across different groups.|In-Processing|Fairness-Constrained Optimisation|Group Fairness|Model Selection & Training|Model-Agnostic|Balancing performance in speech recognition across accents and dialects.|
|**Multi-Accuracy Boosting**|Improves accuracy uniformly across groups by correcting errors where the model performs poorly for certain groups.|In-Processing|Fairness-Constrained Optimisation|Group Fairness|Model Selection & Training|Model-Agnostic|Enhancing model performance for underrepresented groups in disease prediction.|
|**Equalised Odds Post-Processing**|Adjusts output probabilities to equalise true positive and false positive rates across groups.|Post-Processing|Outcome Adjustment|Group Fairness|Model Testing & Validation|Model-Agnostic|Ensuring fairness in recidivism risk assessments used in judicial decisions.|
|**Threshold Optimiser**|Adjusts decision thresholds for different groups to satisfy fairness constraints post-training.|Post-Processing|Outcome Adjustment|Group Fairness|Model Testing & Validation|Model-Agnostic|Ensuring equal acceptance rates in college admissions across demographics.|
|**Reject Option Classification**|Changes decisions where the model is least certain, favouring the disadvantaged group within this uncertain region.|Post-Processing|Outcome Adjustment|Group Fairness|Model Testing & Validation|Model-Agnostic|Mitigating bias in hiring decisions by adjusting uncertain predictions.|
|**Calibration with Equality of Opportunity**|Adjusts probabilities to achieve equal true positive rates across groups while maintaining calibration within each group.|Post-Processing|Calibration Methods|Group Fairness|Model Testing & Validation|Model-Agnostic|Balancing opportunity in credit scoring across different ethnic groups.|
|**Statistical Parity Difference**|Measures the difference in positive outcome rates between protected and unprotected groups.|Fairness Metrics and Evaluation|Group Fairness Metrics|Group Fairness|Data Analysis; Model Testing & Validation|Model-Agnostic|Evaluating fairness in hiring models by comparing selection rates across genders.|
|**Disparate Impact**|Assesses whether decisions disproportionately affect members of a protected group, typically requiring a ratio between rates.|Fairness Metrics and Evaluation|Group Fairness Metrics|Group Fairness|Data Analysis; Model Testing & Validation|Model-Agnostic|Checking for bias in loan approvals where minority groups are less likely to be approved.|
|**Demographic Parity**|Evaluates if the outcome is independent of the protected attributes, aiming for equal outcome rates across groups.|Fairness Metrics and Evaluation|Group Fairness Metrics|Group Fairness|Data Analysis; Model Testing & Validation|Model-Agnostic|Ensuring job advertisements are shown equally across genders.|
|**Equal Opportunity Difference**|Computes the difference in true positive rates between groups, assessing fairness in terms of equal opportunity.|Fairness Metrics and Evaluation|Group Fairness Metrics|Group Fairness|Data Analysis; Model Testing & Validation|Model-Agnostic|Assessing fairness in medical diagnosis models across age groups.|
|**Average Odds Difference**|Calculates the average difference in false positive and true positive rates between groups.|Fairness Metrics and Evaluation|Group Fairness Metrics|Group Fairness|Data Analysis; Model Testing & Validation|Model-Agnostic|Measuring bias in criminal risk assessment tools.|
|**Individual Fairness Metric (Consistency)**|Evaluates whether similar individuals receive similar predictions, assessing fairness at an individual level.|Fairness Metrics and Evaluation|Individual Fairness Metrics|Individual Fairness|Data Analysis; Model Testing & Validation|Model-Agnostic|Ensuring similar credit applicants receive similar loan decisions.|
|**Algorithmic Fairness using K-NN**|Uses K-nearest neighbours to assess individual fairness by comparing predictions among similar instances.|Fairness Metrics and Evaluation|Individual Fairness Metrics|Individual Fairness|Data Analysis; Model Testing & Validation|Model-Agnostic|Evaluating fairness in personalised recommendation systems.|
|**Counterfactual Fairness (Causal Modelling)**|Ensures predictions remain the same in a counterfactual world where protected attributes are altered.|Causal Fairness Methods|Counterfactual Fairness|Individual Fairness|Model Selection & Training|Model-Specific|Assessing fairness in loan approvals by simulating changes in applicant's race.|
|**Path-Specific Counterfactual Fairness**|Considers specific causal pathways, allowing fairness interventions on certain paths.|Causal Fairness Methods|Counterfactual Fairness|Individual Fairness|Model Selection & Training|Model-Specific|Modelling fair decisions in advertising without altering legitimate causal effects.|
|**Causal Fairness Assessment with Do-Calculus**|Utilises causal inference techniques to assess and mitigate bias by computing interventional distributions.|Causal Fairness Methods|Causal Inference|Causal Fairness|Data Analysis; Model Testing & Validation|Model-Specific|Understanding bias in hiring decisions through causal relationships.|
|**Diversity Constraints in Recommendations**|Incorporates diversity and fairness constraints in recommendation systems for varied and fair content exposure.|In-Processing|Fairness-Constrained Optimisation|Group Fairness|Model Selection & Training; System Design and Implementation|Model-Specific|Ensuring fair representation of genres in music recommendation platforms.|
|**Bayesian Fairness Regularisation**|Applies Bayesian methods to include fairness as a prior, allowing probabilistic interpretation of fairness constraints.|In-Processing|Fairness-Constrained Optimisation|Group Fairness|Model Selection & Training|Model-Specific|Applying fairness regularisation in Bayesian models for credit risk assessment.|
|**SHAP Values for Fairness**|Uses SHAP (SHapley Additive exPlanations) to attribute model predictions to input features, helping to identify bias contributions.|Interpretability and Explainability|Feature Attribution Methods|Individual Fairness|Model Testing & Validation; Model Documentation|Model-Agnostic|Explaining biased predictions in loan approvals by examining feature contributions.|
