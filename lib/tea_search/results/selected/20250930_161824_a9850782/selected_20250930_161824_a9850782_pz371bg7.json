{
  "search_id": "20250930_161824_a9850782",
  "technique": {
    "slug": "local-interpretable-model-agnostic-explanations",
    "name": "Local Interpretable Model-Agnostic Explanations",
    "description": "LIME (Local Interpretable Model-agnostic Explanations) explains individual predictions by approximating the complex model's behaviour in a small neighbourhood around a specific instance. It works by creating perturbed versions of the input (e.g., removing words from text, changing pixel values in images, or varying feature values), obtaining the model's predictions for these variations, and training a simple interpretable model (typically linear regression) weighted by proximity to the original instance. The coefficients of this local surrogate model reveal which features most influenced the specific prediction."
  },
  "timestamp": "2025-09-30T16:38:12.456789",
  "selection_summary": {
    "candidates_evaluated": 29,
    "resources_selected": 5,
    "type_distribution": {
      "paper": 2,
      "tool": 1,
      "documentation": 1,
      "tutorial": 1
    }
  },
  "resources": [
    {
      "title": "DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations Approach for Computer-Aided Diagnosis Systems",
      "url": "https://www.semanticscholar.org/paper/e5c703aba8af983c36fedf08c32a6978eadd91b9",
      "type": "paper",
      "relevance_score": 0.95,
      "description": "Highly cited paper (163 citations) addressing LIME's key instability limitation through a deterministic variant, particularly valuable for medical diagnosis applications where consistent explanations are critical."
    },
    {
      "title": "thomasp85/lime",
      "url": "https://github.com/thomasp85/lime",
      "type": "tool",
      "relevance_score": 0.92,
      "description": "Official R implementation of LIME with 489 stars, providing practitioners with a well-maintained tool for applying LIME to R-based machine learning workflows."
    },
    {
      "title": "Local Interpretable Model-Agnostic Explanations (lime) — lime 0.1 documentation",
      "url": "https://lime-ml.readthedocs.io/",
      "type": "documentation",
      "relevance_score": 0.90,
      "description": "Official Python API reference and documentation for the original LIME package, providing authoritative guidance on implementation and usage."
    },
    {
      "title": "Tutorials for eXplainable Artificial Intelligence (XAI) methods — XAI Tutorials",
      "url": "https://xai-tutorials.readthedocs.io/",
      "type": "tutorial",
      "relevance_score": 0.88,
      "description": "Comprehensive Jupyter Notebook-based tutorial collection covering LIME and other XAI methods with practical exercises, ideal for learning and applying LIME in practice."
    },
    {
      "title": "Deterministic Local Interpretable Model-Agnostic Explanations for Stable Explainability",
      "url": "https://www.semanticscholar.org/paper/ee5775e16b00c2a150119c0cb6a4de8c29b30cd3",
      "type": "paper",
      "relevance_score": 0.87,
      "description": "Recent highly cited paper (227 citations) proposing ST-LIME variant to address LIME's instability problem, representing important research direction for improving LIME's reliability."
    }
  ]
}