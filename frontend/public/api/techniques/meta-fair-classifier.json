{
  "slug": "meta-fair-classifier",
  "name": "Meta Fair Classifier",
  "acronym": null,
  "description": "An in-processing fairness technique that employs meta-learning to modify any existing classifier for optimising fairness metrics whilst maintaining predictive performance. The method learns how to adjust model parameters or decision boundaries to satisfy fairness constraints such as demographic parity or equalised odds through iterative optimisation. This approach is particularly valuable when retrofitting fairness to pre-trained models that perform well but exhibit bias, as it can incorporate fairness without requiring complete retraining from scratch.",
  "complexity_rating": 5,
  "computational_cost_rating": 4,
  "assurance_goals": [
    {
      "id": 2,
      "name": "Fairness"
    },
    {
      "id": 6,
      "name": "Transparency"
    },
    {
      "id": 3,
      "name": "Reliability"
    }
  ],
  "tags": [
    {
      "name": "applicable-models/agnostic",
      "id": 1
    },
    {
      "name": "assurance-goal-category/fairness",
      "id": 20
    },
    {
      "name": "assurance-goal-category/fairness/group",
      "id": 22
    },
    {
      "name": "assurance-goal-category/transparency",
      "id": 31
    },
    {
      "name": "assurance-goal-category/reliability",
      "id": 27
    },
    {
      "name": "data-requirements/sensitive-attributes",
      "id": 43
    },
    {
      "name": "data-requirements/labelled-data",
      "id": 38
    },
    {
      "name": "data-type/any",
      "id": 46
    },
    {
      "name": "evidence-type/quantitative-metric",
      "id": 59
    },
    {
      "name": "evidence-type/fairness-metric",
      "id": 54
    },
    {
      "name": "expertise-needed/ml-engineering",
      "id": 73
    },
    {
      "name": "expertise-needed/statistics",
      "id": 79
    },
    {
      "name": "fairness-approach/group",
      "id": 83
    },
    {
      "name": "lifecycle-stage/model-development",
      "id": 92
    },
    {
      "name": "lifecycle-stage/model-development/training",
      "id": 95
    },
    {
      "name": "lifecycle-stage/model-optimization",
      "id": 97
    },
    {
      "name": "technique-type/algorithmic",
      "id": 107
    }
  ],
  "related_techniques": [
    "adversarial-debiasing",
    "fair-adversarial-networks",
    "prejudice-remover-regulariser",
    "exponentiated-gradient-reduction",
    "fair-transfer-learning",
    "adaptive-sensitive-reweighting",
    "multi-accuracy-boosting"
  ],
  "related_technique_slugs": [
    "adversarial-debiasing",
    "fair-adversarial-networks",
    "prejudice-remover-regulariser",
    "exponentiated-gradient-reduction",
    "fair-transfer-learning",
    "adaptive-sensitive-reweighting",
    "multi-accuracy-boosting"
  ],
  "resources": [
    {
      "title": "ρ-Fair Method — holisticai documentation",
      "url": "https://holisticai.readthedocs.io/en/latest/getting_started/bias/mitigation/inprocessing/bc_meta_fair_classifier_rho_fair.html",
      "authors": "",
      "publication_date": null,
      "source_type": "documentation",
      "resource_type": "documentation"
    },
    {
      "title": "aif360.algorithms.inprocessing — aif360 0.1.0 documentation",
      "url": "https://aif360.readthedocs.io/en/v0.2.3/modules/inprocessing.html",
      "authors": "",
      "publication_date": null,
      "source_type": "documentation",
      "resource_type": "documentation"
    },
    {
      "title": "Welcome to AI Fairness 360's documentation! — aif360 0.1.0 ...",
      "url": "https://aif360.readthedocs.io/en/v0.2.3/",
      "authors": "",
      "publication_date": null,
      "source_type": "documentation",
      "resource_type": "documentation"
    },
    {
      "title": "Algorithmic decision making methods for fair credit scoring",
      "url": "http://arxiv.org/abs/2209.07912",
      "authors": ["Moldovan, Darie"],
      "publication_date": "2022-09-16T01:00:00",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    },
    {
      "title": "The Importance of Modeling Data Missingness in Algorithmic Fairness: A\n  Causal Perspective",
      "url": "http://arxiv.org/abs/2012.11448",
      "authors": [
        "Amayuelas, Alfonso",
        "Deshpande, Amit",
        "Goel, Naman",
        "Sharma, Amit"
      ],
      "publication_date": "2020-12-21T00:00:00",
      "source_type": "technical_paper",
      "resource_type": "documentation"
    }
  ],
  "example_use_cases": [
    {
      "description": "Retrofitting an existing hiring algorithm to achieve demographic parity across gender and ethnicity groups by using meta-learning to adjust decision boundaries, ensuring equitable candidate selection whilst maintaining the model's ability to identify qualified applicants.",
      "goal": "Fairness"
    },
    {
      "description": "Modifying a pre-trained credit scoring model to provide transparent fairness guarantees by learning optimal parameter adjustments that satisfy equalised odds constraints, enabling clear reporting on fair lending compliance to regulatory authorities.",
      "goal": "Transparency"
    },
    {
      "description": "Adapting a medical diagnosis model to ensure reliable performance across patient demographics by meta-learning fairness-aware adjustments that maintain diagnostic accuracy whilst reducing disparities in treatment recommendations across age and socioeconomic groups.",
      "goal": "Reliability"
    }
  ],
  "limitations": [
    {
      "description": "Meta-learning approach can be complex to implement, requiring expertise in both the underlying classifier and meta-optimisation techniques."
    },
    {
      "description": "Requires extensive hyperparameter tuning to balance fairness constraints with predictive performance, making optimisation challenging."
    },
    {
      "description": "May result in longer training times compared to simpler fairness techniques due to the iterative meta-learning process."
    },
    {
      "description": "Performance depends heavily on the quality and characteristics of the base classifier being modified, limiting effectiveness with poorly-performing models."
    },
    {
      "description": "Theoretical guarantees about fairness-accuracy trade-offs may not hold in practice due to finite sample effects and optimisation challenges."
    }
  ]
}
