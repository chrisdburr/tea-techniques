{
  "search_id": "20250930_161824_a9850782",
  "technique": {
    "slug": "local-interpretable-model-agnostic-explanations",
    "name": "Local Interpretable Model-Agnostic Explanations",
    "description": "LIME (Local Interpretable Model-agnostic Explanations) explains individual predictions by approximating the complex model's behaviour in a small neighbourhood around a specific instance. It works by creating perturbed versions of the input (e.g., removing words from text, changing pixel values in images, or varying feature values), obtaining the model's predictions for these variations, and training a simple interpretable model (typically linear regression) weighted by proximity to the original instance. The coefficients of this local surrogate model reveal which features most influenced the specific prediction."
  },
  "timestamp": "2025-09-30T16:35:45.123456",
  "selection_summary": {
    "candidates_evaluated": 29,
    "resources_selected": 5,
    "type_distribution": {
      "paper": 2,
      "tool": 1,
      "documentation": 1,
      "tutorial": 1
    }
  },
  "resources": [
    {
      "title": "DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations Approach for Computer-Aided Diagnosis Systems",
      "url": "https://www.semanticscholar.org/paper/e5c703aba8af983c36fedf08c32a6978eadd91b9",
      "type": "paper",
      "relevance_score": 0.95,
      "description": "Highly cited (163 citations) deterministic variant of LIME that addresses the technique's key instability limitation through fixed perturbation strategies, particularly valuable for medical diagnosis applications."
    },
    {
      "title": "thomasp85/lime",
      "url": "https://github.com/thomasp85/lime",
      "type": "tool",
      "relevance_score": 0.92,
      "description": "Official R implementation of LIME with 489 stars, providing a well-maintained and production-ready tool for R users working with caret and other ML frameworks."
    },
    {
      "title": "Local Interpretable Model-Agnostic Explanations (lime) — lime 0.1 documentation",
      "url": "https://lime-ml.readthedocs.io/",
      "type": "documentation",
      "relevance_score": 0.90,
      "description": "Official Python API reference documentation for the LIME package, serving as the authoritative technical reference for implementation details and usage patterns."
    },
    {
      "title": "Tutorials for eXplainable Artificial Intelligence (XAI) methods — XAI Tutorials",
      "url": "https://xai-tutorials.readthedocs.io/",
      "type": "tutorial",
      "relevance_score": 0.88,
      "description": "Comprehensive tutorial collection featuring LIME and other XAI methods with practical Jupyter Notebook exercises, ideal for hands-on learning and comparing techniques."
    },
    {
      "title": "Deterministic Local Interpretable Model-Agnostic Explanations for Stable Explainability",
      "url": "https://www.semanticscholar.org/paper/ee5775e16b00c2a150119c0cb6a4de8c29b30cd3",
      "type": "paper",
      "relevance_score": 0.87,
      "description": "Highly cited (227 citations) paper proposing a deterministic variant that addresses LIME's instability through fixed noise generation, providing theoretical foundations for improved explainability."
    }
  ]
}