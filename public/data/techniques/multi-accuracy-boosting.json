{
  "slug": "multi-accuracy-boosting",
  "name": "Multi-Accuracy Boosting",
  "description": "An in-processing fairness technique that employs boosting algorithms to improve accuracy uniformly across demographic groups by iteratively correcting errors where the model performs poorly for certain subgroups. The method uses a multi-calibration approach that trains weak learners to focus on prediction errors for underperforming groups, ensuring that no group experiences systematically worse accuracy. This iterative boosting process continues until accuracy parity is achieved across all groups whilst maintaining overall model performance.",
  "assurance_goals": [
    "Fairness",
    "Reliability",
    "Transparency"
  ],
  "tags": [
    "applicable-models/architecture/ensemble",
    "applicable-models/paradigm/discriminative",
    "applicable-models/paradigm/supervised",
    "applicable-models/requirements/training-data",
    "applicable-models/requirements/white-box",
    "assurance-goal-category/fairness",
    "assurance-goal-category/fairness/group",
    "assurance-goal-category/reliability",
    "assurance-goal-category/transparency",
    "data-requirements/labelled-data",
    "data-requirements/sensitive-attributes",
    "data-type/any",
    "evidence-type/fairness-metric",
    "evidence-type/quantitative-metric",
    "expertise-needed/ml-engineering",
    "expertise-needed/statistics",
    "fairness-approach/group",
    "lifecycle-stage/model-development",
    "lifecycle-stage/model-development/training",
    "technique-type/algorithmic"
  ],
  "example_use_cases": [
    {
      "description": "Training a medical diagnosis model that achieves equal accuracy across age, gender, and ethnicity groups by using boosting to specifically target prediction errors for underrepresented patient demographics, ensuring equitable healthcare outcomes for all populations.",
      "goal": "Fairness"
    },
    {
      "description": "Building a robust fraud detection system that maintains consistent accuracy across different customer segments by iteratively correcting errors where the model performs poorly for specific demographic or geographic groups, ensuring reliable fraud prevention across all user types.",
      "goal": "Reliability"
    },
    {
      "description": "Developing a transparent hiring algorithm that provides clear evidence of equal performance across candidate demographics by using multi-accuracy boosting to systematically address group-specific prediction errors, enabling auditable fair recruitment processes.",
      "goal": "Transparency"
    }
  ],
  "limitations": [
    {
      "description": "Requires identifying and defining relevant subgroups or error regions, which may be challenging when group boundaries are unclear or overlapping."
    },
    {
      "description": "Could increase model complexity significantly as the boosting process adds multiple weak learners, potentially affecting interpretability and computational efficiency."
    },
    {
      "description": "May overfit to training data if very granular corrections are made, particularly when subgroups are small or the boosting process continues for too many iterations."
    },
    {
      "description": "Performance depends on the quality of subgroup identification, and may fail to achieve fairness if important demographic intersections are not properly captured."
    },
    {
      "description": "Convergence to equal accuracy across groups is not guaranteed, especially when there are fundamental differences in data distributions between groups."
    }
  ],
  "resources": [
    {
      "title": "mcboost: Multi-Calibration Boosting for R",
      "url": "https://joss.theoj.org/papers/10.21105/joss.03453",
      "source_type": "technical_paper",
      "authors": [
        "Bernd Bischl",
        "Susanne Dandl",
        "Christoph Kern",
        "Michael P. Kim",
        "Florian Pfisterer",
        "Matthew Sun"
      ],
      "publication_date": "2021-08-24"
    },
    {
      "title": "mlr-org/mcboost",
      "url": "https://github.com/mlr-org/mcboost",
      "source_type": "software_package"
    },
    {
      "title": "Multigroup Robustness",
      "url": "http://arxiv.org/abs/2405.00614",
      "source_type": "technical_paper",
      "authors": [
        "Lunjia Hu",
        "Charlotte Peale",
        "Judy Hanwen Shen"
      ],
      "publication_date": "2024-05-01"
    }
  ],
  "complexity_rating": 5,
  "computational_cost_rating": 4,
  "related_techniques": [
    "adversarial-debiasing",
    "fair-adversarial-networks",
    "prejudice-remover-regulariser",
    "meta-fair-classifier",
    "exponentiated-gradient-reduction",
    "fair-transfer-learning",
    "adaptive-sensitive-reweighting"
  ]
}